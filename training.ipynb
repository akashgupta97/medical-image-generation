{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bfb6d-5836-47cf-97b6-91050dde603f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6767c-b87d-4728-bb06-11c7cebe86a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            list_data = f.readlines()\n",
    "            self.data = [json.loads(a) for a in list_data]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "\n",
    "        source_filename = item['source']\n",
    "        target_filename = item['target']\n",
    "        prompt = item['prompt']\n",
    "\n",
    "        source = cv2.imread(source_filename)\n",
    "        target = cv2.imread(target_filename)\n",
    "        dim = (512,512)\n",
    "        print()\n",
    "        source = cv2.resize(source, dim, interpolation = cv2.INTER_CUBIC)\n",
    "        target = cv2.resize(target, dim, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        # Do not forget that OpenCV read images in BGR order.\n",
    "        source = cv2.cvtColor(source, cv2.COLOR_BGR2RGB)\n",
    "        target = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Normalize source images to [0, 1].\n",
    "        source = source.astype(np.float32) / 255.0\n",
    "\n",
    "        # Normalize target images to [-1, 1].\n",
    "        target = (target.astype(np.float32) / 127.5) - 1.0\n",
    "\n",
    "        return dict(jpg=target, txt=prompt, hint=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318923ae-8137-4d5c-b731-67342fbe305f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset(\"/home/jupyter/gcs/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb8ff7-43ed-4fbf-9ea2-95163c660dbd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'jpg': array([[[-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ]],\n",
       " \n",
       "        [[-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-0.8117647 , -0.8117647 , -0.8117647 ],\n",
       "         [-0.81960785, -0.81960785, -0.81960785],\n",
       "         [-0.81960785, -0.81960785, -0.81960785]],\n",
       " \n",
       "        [[-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-0.8039216 , -0.8039216 , -0.8039216 ],\n",
       "         [-0.8117647 , -0.8117647 , -0.8117647 ],\n",
       "         [-0.79607844, -0.79607844, -0.79607844]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.19215691,  0.19215691,  0.19215691],\n",
       "         [ 0.16078436,  0.16078436,  0.16078436],\n",
       "         [ 0.082353  ,  0.082353  ,  0.082353  ]],\n",
       " \n",
       "        [[-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.17647064,  0.17647064,  0.17647064],\n",
       "         [ 0.14509809,  0.14509809,  0.14509809],\n",
       "         [ 0.10588241,  0.10588241,  0.10588241]],\n",
       " \n",
       "        [[-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-0.5686275 , -0.5686275 , -0.5686275 ],\n",
       "         [-0.58431375, -0.58431375, -0.58431375],\n",
       "         [-0.5764706 , -0.5764706 , -0.5764706 ]]], dtype=float32),\n",
       " 'txt': 'a chest xray with No Finding',\n",
       " 'hint': array([[[0.26666668, 0.00392157, 0.32941177],\n",
       "         [0.26666668, 0.        , 0.30980393],\n",
       "         [0.2627451 , 0.04705882, 0.3882353 ],\n",
       "         ...,\n",
       "         [0.14509805, 0.7019608 , 0.52156866],\n",
       "         [0.23921569, 0.8       , 0.45490196],\n",
       "         [0.3254902 , 0.827451  , 0.4117647 ]],\n",
       " \n",
       "        [[0.26666668, 0.00392157, 0.32941177],\n",
       "         [0.26666668, 0.        , 0.30980393],\n",
       "         [0.27058825, 0.04313726, 0.38039216],\n",
       "         ...,\n",
       "         [0.21960784, 0.27450982, 0.40784314],\n",
       "         [0.25490198, 0.3137255 , 0.38431373],\n",
       "         [0.2901961 , 0.32156864, 0.36862746]],\n",
       " \n",
       "        [[0.26666668, 0.00392157, 0.32941177],\n",
       "         [0.26666668, 0.        , 0.30980393],\n",
       "         [0.27450982, 0.04313726, 0.3764706 ],\n",
       "         ...,\n",
       "         [0.2784314 , 0.        , 0.31764707],\n",
       "         [0.27058825, 0.        , 0.3254902 ],\n",
       "         [0.2627451 , 0.        , 0.32941177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.26666668, 0.00392157, 0.32941177],\n",
       "         [0.26666668, 0.        , 0.30980393],\n",
       "         [0.2509804 , 0.03921569, 0.39607844],\n",
       "         ...,\n",
       "         [0.77254903, 0.8509804 , 0.16862746],\n",
       "         [0.7764706 , 0.8235294 , 0.16862746],\n",
       "         [0.7607843 , 0.73333335, 0.18431373]],\n",
       " \n",
       "        [[0.26666668, 0.00392157, 0.32941177],\n",
       "         [0.26666668, 0.        , 0.30980393],\n",
       "         [0.25490198, 0.03921569, 0.39215687],\n",
       "         ...,\n",
       "         [0.69803923, 0.8509804 , 0.20392157],\n",
       "         [0.6901961 , 0.85882354, 0.20392157],\n",
       "         [0.65882355, 0.8862745 , 0.2       ]],\n",
       " \n",
       "        [[0.26666668, 0.00392157, 0.32941177],\n",
       "         [0.26666668, 0.        , 0.30980393],\n",
       "         [0.2784314 , 0.03529412, 0.37254903],\n",
       "         ...,\n",
       "         [0.16862746, 0.7137255 , 0.49019608],\n",
       "         [0.16470589, 0.70980394, 0.49411765],\n",
       "         [0.16078432, 0.70980394, 0.49411765]]], dtype=float32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82372b41-472c-4103-901d-f679036707dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a chest xray with No Finding\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "item = dataset[0]\n",
    "jpg = item['jpg']\n",
    "txt = item['txt']\n",
    "hint = item['hint']\n",
    "print(txt)\n",
    "print(jpg.shape)\n",
    "print(hint.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92465f4-d485-4c74-ae93-d5b45f638abd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ControlNet/\")\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from ControlNet.cldm.logger import ImageLogger\n",
    "from ControlNet.cldm.model import create_model, load_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0d6f8-1baf-4388-81c4-606424d5bdf6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControlLDM: Running in eps-prediction mode\n",
      "DiffusionWrapper has 865.91 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Loaded model config from [ControlNet/models/cldm_v21.yaml]\n",
      "Loaded state_dict from [/home/jupyter/gcs/checkpoints/control_sd21_ini.ckpt]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/opt/conda/envs/control/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:118: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "/opt/conda/envs/control/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:280: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/opt/conda/envs/control/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:287: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                   | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model             | DiffusionWrapper       | 865 M \n",
      "1 | first_stage_model | AutoencoderKL          | 83.7 M\n",
      "2 | cond_stage_model  | FrozenOpenCLIPEmbedder | 354 M \n",
      "3 | control_model     | ControlNet             | 364 M \n",
      "-------------------------------------------------------------\n",
      "1.2 B     Trainable params\n",
      "437 M     Non-trainable params\n",
      "1.7 B     Total params\n",
      "6,671.302 Total estimated model params size (MB)\n",
      "/opt/conda/envs/control/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/20881 [00:00<?, ?it/s] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/control/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▏         | 1/50 [00:00<00:22,  2.20it/s]\u001b[A\n",
      "DDIM Sampler:   4%|▍         | 2/50 [00:00<00:21,  2.20it/s]\u001b[A\n",
      "DDIM Sampler:   6%|▌         | 3/50 [00:01<00:21,  2.20it/s]\u001b[A\n",
      "DDIM Sampler:   8%|▊         | 4/50 [00:01<00:20,  2.20it/s]\u001b[A\n",
      "DDIM Sampler:  10%|█         | 5/50 [00:02<00:20,  2.20it/s]\u001b[A\n",
      "DDIM Sampler:  12%|█▏        | 6/50 [00:02<00:19,  2.20it/s]\u001b[A\n",
      "DDIM Sampler:  14%|█▍        | 7/50 [00:03<00:19,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  16%|█▌        | 8/50 [00:03<00:19,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█▊        | 9/50 [00:04<00:18,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  20%|██        | 10/50 [00:04<00:18,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██▏       | 11/50 [00:04<00:17,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██▍       | 12/50 [00:05<00:17,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  26%|██▌       | 13/50 [00:05<00:16,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  28%|██▊       | 14/50 [00:06<00:16,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  30%|███       | 15/50 [00:06<00:15,  2.20it/s]\u001b[A\n",
      "DDIM Sampler:  32%|███▏      | 16/50 [00:07<00:15,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  34%|███▍      | 17/50 [00:07<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  36%|███▌      | 18/50 [00:08<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███▊      | 19/50 [00:08<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  40%|████      | 20/50 [00:09<00:13,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████▏     | 21/50 [00:09<00:13,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████▍     | 22/50 [00:09<00:12,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  46%|████▌     | 23/50 [00:10<00:12,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  48%|████▊     | 24/50 [00:10<00:11,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  50%|█████     | 25/50 [00:11<00:11,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  52%|█████▏    | 26/50 [00:11<00:10,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  54%|█████▍    | 27/50 [00:12<00:10,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  56%|█████▌    | 28/50 [00:12<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  58%|█████▊    | 29/50 [00:13<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  60%|██████    | 30/50 [00:13<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  62%|██████▏   | 31/50 [00:14<00:08,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████▍   | 32/50 [00:14<00:08,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  66%|██████▌   | 33/50 [00:14<00:07,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  68%|██████▊   | 34/50 [00:15<00:07,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  70%|███████   | 35/50 [00:15<00:06,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  72%|███████▏  | 36/50 [00:16<00:06,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  74%|███████▍  | 37/50 [00:16<00:05,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  76%|███████▌  | 38/50 [00:17<00:05,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  78%|███████▊  | 39/50 [00:17<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  80%|████████  | 40/50 [00:18<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  82%|████████▏ | 41/50 [00:18<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████▍ | 42/50 [00:19<00:03,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████▌ | 43/50 [00:19<00:03,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  88%|████████▊ | 44/50 [00:19<00:02,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  90%|█████████ | 45/50 [00:20<00:02,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  92%|█████████▏| 46/50 [00:20<00:01,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  94%|█████████▍| 47/50 [00:21<00:01,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  96%|█████████▌| 48/50 [00:21<00:00,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  98%|█████████▊| 49/50 [00:22<00:00,  2.20it/s]\u001b[A\n",
      "DDIM Sampler: 100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/20881 [00:49<288:28:41, 49.74s/it, loss=0.161, v_num=0, train/loss_simple_step=0.161, train/loss_vlb_step=0.00183, train/loss_step=0.161, global_step=0.000]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 2/20881 [00:54<157:34:04, 27.17s/it, loss=0.148, v_num=0, train/loss_simple_step=0.135, train/loss_vlb_step=0.0017, train/loss_step=0.135, global_step=1.000] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 3/20881 [00:59<115:45:30, 19.96s/it, loss=0.134, v_num=0, train/loss_simple_step=0.107, train/loss_vlb_step=0.000606, train/loss_step=0.107, global_step=2.000]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 4/20881 [01:05<94:17:37, 16.26s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0624, train/loss_vlb_step=0.00025, train/loss_step=0.0624, global_step=3.000]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 5/20881 [01:10<81:58:12, 14.14s/it, loss=0.0967, v_num=0, train/loss_simple_step=0.0185, train/loss_vlb_step=7.39e-5, train/loss_step=0.0185, global_step=4.000]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 6/20881 [01:16<74:01:32, 12.77s/it, loss=0.0999, v_num=0, train/loss_simple_step=0.116, train/loss_vlb_step=0.000616, train/loss_step=0.116, global_step=5.000] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 7/20881 [01:22<68:01:36, 11.73s/it, loss=0.0941, v_num=0, train/loss_simple_step=0.0596, train/loss_vlb_step=0.000273, train/loss_step=0.0596, global_step=6.000]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 8/20881 [01:27<63:33:50, 10.96s/it, loss=0.107, v_num=0, train/loss_simple_step=0.193, train/loss_vlb_step=0.0183, train/loss_step=0.193, global_step=7.000]     \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 9/20881 [01:33<60:20:18, 10.41s/it, loss=0.116, v_num=0, train/loss_simple_step=0.196, train/loss_vlb_step=0.00228, train/loss_step=0.196, global_step=8.000]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 10/20881 [01:41<58:41:30, 10.12s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0944, train/loss_vlb_step=0.000613, train/loss_step=0.0944, global_step=9.000]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 11/20881 [01:47<56:39:43,  9.77s/it, loss=0.116, v_num=0, train/loss_simple_step=0.135, train/loss_vlb_step=0.00141, train/loss_step=0.135, global_step=10.00]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 12/20881 [01:53<54:52:43,  9.47s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0629, train/loss_vlb_step=0.000279, train/loss_step=0.0629, global_step=11.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 13/20881 [02:00<53:46:46,  9.28s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0731, train/loss_vlb_step=0.000251, train/loss_step=0.0731, global_step=12.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 14/20881 [02:06<52:19:03,  9.03s/it, loss=0.112, v_num=0, train/loss_simple_step=0.161, train/loss_vlb_step=0.000682, train/loss_step=0.161, global_step=13.00]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 15/20881 [02:11<50:54:34,  8.78s/it, loss=0.113, v_num=0, train/loss_simple_step=0.125, train/loss_vlb_step=0.000598, train/loss_step=0.125, global_step=14.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 16/20881 [02:16<49:26:20,  8.53s/it, loss=0.115, v_num=0, train/loss_simple_step=0.137, train/loss_vlb_step=0.000784, train/loss_step=0.137, global_step=15.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 17/20881 [02:21<48:07:26,  8.30s/it, loss=0.115, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.000702, train/loss_step=0.124, global_step=16.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 18/20881 [02:27<47:26:33,  8.19s/it, loss=0.116, v_num=0, train/loss_simple_step=0.123, train/loss_vlb_step=0.000824, train/loss_step=0.123, global_step=17.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 19/20881 [02:32<46:25:11,  8.01s/it, loss=0.115, v_num=0, train/loss_simple_step=0.102, train/loss_vlb_step=0.000365, train/loss_step=0.102, global_step=18.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 20/20881 [02:38<46:00:56,  7.94s/it, loss=0.118, v_num=0, train/loss_simple_step=0.174, train/loss_vlb_step=0.00112, train/loss_step=0.174, global_step=19.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 21/20881 [02:44<45:28:53,  7.85s/it, loss=0.117, v_num=0, train/loss_simple_step=0.142, train/loss_vlb_step=0.000683, train/loss_step=0.142, global_step=20.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 22/20881 [02:50<44:52:20,  7.74s/it, loss=0.117, v_num=0, train/loss_simple_step=0.143, train/loss_vlb_step=0.000567, train/loss_step=0.143, global_step=21.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 23/20881 [02:56<44:23:38,  7.66s/it, loss=0.118, v_num=0, train/loss_simple_step=0.117, train/loss_vlb_step=0.000934, train/loss_step=0.117, global_step=22.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 24/20881 [03:01<43:46:28,  7.56s/it, loss=0.121, v_num=0, train/loss_simple_step=0.127, train/loss_vlb_step=0.000491, train/loss_step=0.127, global_step=23.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 25/20881 [03:06<43:11:05,  7.45s/it, loss=0.123, v_num=0, train/loss_simple_step=0.0505, train/loss_vlb_step=0.000186, train/loss_step=0.0505, global_step=24.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 26/20881 [03:10<42:31:18,  7.34s/it, loss=0.118, v_num=0, train/loss_simple_step=0.0192, train/loss_vlb_step=7.45e-5, train/loss_step=0.0192, global_step=25.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 27/20881 [03:16<42:12:14,  7.29s/it, loss=0.122, v_num=0, train/loss_simple_step=0.148, train/loss_vlb_step=0.000661, train/loss_step=0.148, global_step=26.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 28/20881 [03:21<41:41:52,  7.20s/it, loss=0.125, v_num=0, train/loss_simple_step=0.243, train/loss_vlb_step=0.00672, train/loss_step=0.243, global_step=27.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 29/20881 [03:27<41:25:19,  7.15s/it, loss=0.121, v_num=0, train/loss_simple_step=0.110, train/loss_vlb_step=0.000511, train/loss_step=0.110, global_step=28.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 30/20881 [03:33<41:11:05,  7.11s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0637, train/loss_vlb_step=0.000235, train/loss_step=0.0637, global_step=29.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 31/20881 [03:40<41:08:17,  7.10s/it, loss=0.121, v_num=0, train/loss_simple_step=0.165, train/loss_vlb_step=0.000788, train/loss_step=0.165, global_step=30.00]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 32/20881 [03:46<40:56:38,  7.07s/it, loss=0.12, v_num=0, train/loss_simple_step=0.052, train/loss_vlb_step=0.000211, train/loss_step=0.052, global_step=31.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 33/20881 [03:52<40:51:52,  7.06s/it, loss=0.123, v_num=0, train/loss_simple_step=0.139, train/loss_vlb_step=0.000713, train/loss_step=0.139, global_step=32.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 34/20881 [03:59<40:46:20,  7.04s/it, loss=0.122, v_num=0, train/loss_simple_step=0.135, train/loss_vlb_step=0.000653, train/loss_step=0.135, global_step=33.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 35/20881 [04:06<40:44:51,  7.04s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0559, train/loss_vlb_step=0.00022, train/loss_step=0.0559, global_step=34.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 36/20881 [04:12<40:40:13,  7.02s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0409, train/loss_vlb_step=0.000144, train/loss_step=0.0409, global_step=35.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 37/20881 [04:17<40:19:33,  6.96s/it, loss=0.116, v_num=0, train/loss_simple_step=0.171, train/loss_vlb_step=0.00137, train/loss_step=0.171, global_step=36.00]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 38/20881 [04:23<40:08:55,  6.93s/it, loss=0.115, v_num=0, train/loss_simple_step=0.0933, train/loss_vlb_step=0.000372, train/loss_step=0.0933, global_step=37.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 39/20881 [04:29<39:59:15,  6.91s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0693, train/loss_vlb_step=0.00035, train/loss_step=0.0693, global_step=38.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 40/20881 [04:34<39:41:35,  6.86s/it, loss=0.112, v_num=0, train/loss_simple_step=0.154, train/loss_vlb_step=0.000806, train/loss_step=0.154, global_step=39.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 41/20881 [04:39<39:27:46,  6.82s/it, loss=0.112, v_num=0, train/loss_simple_step=0.151, train/loss_vlb_step=0.000808, train/loss_step=0.151, global_step=40.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 42/20881 [04:44<39:14:17,  6.78s/it, loss=0.113, v_num=0, train/loss_simple_step=0.148, train/loss_vlb_step=0.00161, train/loss_step=0.148, global_step=41.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 43/20881 [04:49<38:57:57,  6.73s/it, loss=0.118, v_num=0, train/loss_simple_step=0.222, train/loss_vlb_step=0.0015, train/loss_step=0.222, global_step=42.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 44/20881 [04:55<38:49:52,  6.71s/it, loss=0.117, v_num=0, train/loss_simple_step=0.115, train/loss_vlb_step=0.0012, train/loss_step=0.115, global_step=43.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 45/20881 [05:00<38:37:11,  6.67s/it, loss=0.125, v_num=0, train/loss_simple_step=0.209, train/loss_vlb_step=0.00105, train/loss_step=0.209, global_step=44.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 46/20881 [05:05<38:29:45,  6.65s/it, loss=0.132, v_num=0, train/loss_simple_step=0.164, train/loss_vlb_step=0.00107, train/loss_step=0.164, global_step=45.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 47/20881 [05:14<38:43:15,  6.69s/it, loss=0.129, v_num=0, train/loss_simple_step=0.0734, train/loss_vlb_step=0.000323, train/loss_step=0.0734, global_step=46.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 48/20881 [05:22<38:52:28,  6.72s/it, loss=0.123, v_num=0, train/loss_simple_step=0.132, train/loss_vlb_step=0.000635, train/loss_step=0.132, global_step=47.00]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 49/20881 [05:28<38:50:12,  6.71s/it, loss=0.124, v_num=0, train/loss_simple_step=0.135, train/loss_vlb_step=0.000672, train/loss_step=0.135, global_step=48.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 50/20881 [05:34<38:43:45,  6.69s/it, loss=0.132, v_num=0, train/loss_simple_step=0.205, train/loss_vlb_step=0.00939, train/loss_step=0.205, global_step=49.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 51/20881 [05:40<38:36:08,  6.67s/it, loss=0.128, v_num=0, train/loss_simple_step=0.101, train/loss_vlb_step=0.000398, train/loss_step=0.101, global_step=50.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 52/20881 [05:45<38:25:47,  6.64s/it, loss=0.129, v_num=0, train/loss_simple_step=0.0649, train/loss_vlb_step=0.000336, train/loss_step=0.0649, global_step=51.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 53/20881 [05:51<38:20:33,  6.63s/it, loss=0.125, v_num=0, train/loss_simple_step=0.0525, train/loss_vlb_step=0.000209, train/loss_step=0.0525, global_step=52.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 54/20881 [05:56<38:13:49,  6.61s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0141, train/loss_vlb_step=5.78e-5, train/loss_step=0.0141, global_step=53.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 55/20881 [06:02<38:08:31,  6.59s/it, loss=0.121, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000449, train/loss_step=0.104, global_step=54.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 56/20881 [06:08<38:02:39,  6.58s/it, loss=0.122, v_num=0, train/loss_simple_step=0.0668, train/loss_vlb_step=0.000228, train/loss_step=0.0668, global_step=55.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 57/20881 [06:13<37:56:57,  6.56s/it, loss=0.126, v_num=0, train/loss_simple_step=0.237, train/loss_vlb_step=0.00337, train/loss_step=0.237, global_step=56.00]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 58/20881 [06:19<37:52:53,  6.55s/it, loss=0.124, v_num=0, train/loss_simple_step=0.0716, train/loss_vlb_step=0.00027, train/loss_step=0.0716, global_step=57.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 59/20881 [06:25<37:46:58,  6.53s/it, loss=0.126, v_num=0, train/loss_simple_step=0.0898, train/loss_vlb_step=0.000318, train/loss_step=0.0898, global_step=58.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 60/20881 [06:30<37:37:56,  6.51s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0201, train/loss_vlb_step=7.51e-5, train/loss_step=0.0201, global_step=59.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 61/20881 [06:35<37:29:53,  6.48s/it, loss=0.12, v_num=0, train/loss_simple_step=0.176, train/loss_vlb_step=0.00454, train/loss_step=0.176, global_step=60.00]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 62/20881 [06:41<37:25:10,  6.47s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0642, train/loss_vlb_step=0.000231, train/loss_step=0.0642, global_step=61.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 63/20881 [06:46<37:17:54,  6.45s/it, loss=0.113, v_num=0, train/loss_simple_step=0.155, train/loss_vlb_step=0.00104, train/loss_step=0.155, global_step=62.00]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 64/20881 [06:51<37:10:52,  6.43s/it, loss=0.11, v_num=0, train/loss_simple_step=0.067, train/loss_vlb_step=0.000266, train/loss_step=0.067, global_step=63.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 65/20881 [06:56<37:03:48,  6.41s/it, loss=0.108, v_num=0, train/loss_simple_step=0.170, train/loss_vlb_step=0.00195, train/loss_step=0.170, global_step=64.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 66/20881 [07:01<36:54:04,  6.38s/it, loss=0.106, v_num=0, train/loss_simple_step=0.120, train/loss_vlb_step=0.000739, train/loss_step=0.120, global_step=65.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 67/20881 [07:06<36:48:04,  6.37s/it, loss=0.114, v_num=0, train/loss_simple_step=0.226, train/loss_vlb_step=0.00318, train/loss_step=0.226, global_step=66.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 68/20881 [07:11<36:42:54,  6.35s/it, loss=0.123, v_num=0, train/loss_simple_step=0.319, train/loss_vlb_step=0.00447, train/loss_step=0.319, global_step=67.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 69/20881 [07:17<36:37:20,  6.33s/it, loss=0.118, v_num=0, train/loss_simple_step=0.0272, train/loss_vlb_step=9.63e-5, train/loss_step=0.0272, global_step=68.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 70/20881 [07:21<36:29:10,  6.31s/it, loss=0.114, v_num=0, train/loss_simple_step=0.142, train/loss_vlb_step=0.00135, train/loss_step=0.142, global_step=69.00]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 71/20881 [07:26<36:21:44,  6.29s/it, loss=0.116, v_num=0, train/loss_simple_step=0.129, train/loss_vlb_step=0.00052, train/loss_step=0.129, global_step=70.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 72/20881 [07:32<36:18:24,  6.28s/it, loss=0.12, v_num=0, train/loss_simple_step=0.158, train/loss_vlb_step=0.00227, train/loss_step=0.158, global_step=71.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 73/20881 [07:37<36:12:41,  6.26s/it, loss=0.12, v_num=0, train/loss_simple_step=0.0401, train/loss_vlb_step=0.000137, train/loss_step=0.0401, global_step=72.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 74/20881 [07:42<36:09:16,  6.26s/it, loss=0.128, v_num=0, train/loss_simple_step=0.172, train/loss_vlb_step=0.000969, train/loss_step=0.172, global_step=73.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 75/20881 [07:47<36:03:12,  6.24s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0983, train/loss_vlb_step=0.00084, train/loss_step=0.0983, global_step=74.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 76/20881 [07:52<35:58:03,  6.22s/it, loss=0.141, v_num=0, train/loss_simple_step=0.342, train/loss_vlb_step=0.0184, train/loss_step=0.342, global_step=75.00]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 77/20881 [07:59<35:59:01,  6.23s/it, loss=0.131, v_num=0, train/loss_simple_step=0.029, train/loss_vlb_step=0.000104, train/loss_step=0.029, global_step=76.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 78/20881 [08:05<35:57:39,  6.22s/it, loss=0.131, v_num=0, train/loss_simple_step=0.0764, train/loss_vlb_step=0.000275, train/loss_step=0.0764, global_step=77.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 79/20881 [08:10<35:52:35,  6.21s/it, loss=0.129, v_num=0, train/loss_simple_step=0.0557, train/loss_vlb_step=0.000189, train/loss_step=0.0557, global_step=78.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 80/20881 [08:16<35:52:01,  6.21s/it, loss=0.138, v_num=0, train/loss_simple_step=0.193, train/loss_vlb_step=0.00162, train/loss_step=0.193, global_step=79.00]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 81/20881 [08:22<35:52:42,  6.21s/it, loss=0.136, v_num=0, train/loss_simple_step=0.146, train/loss_vlb_step=0.000761, train/loss_step=0.146, global_step=80.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 82/20881 [08:29<35:51:51,  6.21s/it, loss=0.136, v_num=0, train/loss_simple_step=0.062, train/loss_vlb_step=0.000218, train/loss_step=0.062, global_step=81.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 83/20881 [08:34<35:48:05,  6.20s/it, loss=0.139, v_num=0, train/loss_simple_step=0.205, train/loss_vlb_step=0.00326, train/loss_step=0.205, global_step=82.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 84/20881 [08:39<35:45:12,  6.19s/it, loss=0.145, v_num=0, train/loss_simple_step=0.196, train/loss_vlb_step=0.006, train/loss_step=0.196, global_step=83.00]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 85/20881 [08:44<35:40:16,  6.18s/it, loss=0.144, v_num=0, train/loss_simple_step=0.146, train/loss_vlb_step=0.00265, train/loss_step=0.146, global_step=84.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 86/20881 [08:50<35:38:12,  6.17s/it, loss=0.139, v_num=0, train/loss_simple_step=0.0148, train/loss_vlb_step=5.6e-5, train/loss_step=0.0148, global_step=85.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 87/20881 [08:57<35:39:52,  6.17s/it, loss=0.13, v_num=0, train/loss_simple_step=0.0501, train/loss_vlb_step=0.000169, train/loss_step=0.0501, global_step=86.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 88/20881 [09:01<35:33:29,  6.16s/it, loss=0.123, v_num=0, train/loss_simple_step=0.178, train/loss_vlb_step=0.00126, train/loss_step=0.178, global_step=87.00]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 89/20881 [09:07<35:30:10,  6.15s/it, loss=0.124, v_num=0, train/loss_simple_step=0.0503, train/loss_vlb_step=0.000187, train/loss_step=0.0503, global_step=88.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 90/20881 [09:11<35:23:54,  6.13s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0356, train/loss_vlb_step=0.000129, train/loss_step=0.0356, global_step=89.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 91/20881 [09:16<35:19:44,  6.12s/it, loss=0.115, v_num=0, train/loss_simple_step=0.0445, train/loss_vlb_step=0.000154, train/loss_step=0.0445, global_step=90.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 92/20881 [09:21<35:15:59,  6.11s/it, loss=0.117, v_num=0, train/loss_simple_step=0.195, train/loss_vlb_step=0.00424, train/loss_step=0.195, global_step=91.00]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 93/20881 [09:26<35:12:05,  6.10s/it, loss=0.123, v_num=0, train/loss_simple_step=0.176, train/loss_vlb_step=0.00298, train/loss_step=0.176, global_step=92.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 94/20881 [09:32<35:09:17,  6.09s/it, loss=0.125, v_num=0, train/loss_simple_step=0.208, train/loss_vlb_step=0.00905, train/loss_step=0.208, global_step=93.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 95/20881 [09:36<35:03:59,  6.07s/it, loss=0.124, v_num=0, train/loss_simple_step=0.076, train/loss_vlb_step=0.000284, train/loss_step=0.076, global_step=94.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 96/20881 [09:42<35:00:35,  6.06s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0353, train/loss_vlb_step=0.00013, train/loss_step=0.0353, global_step=95.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 97/20881 [09:48<35:00:37,  6.06s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0339, train/loss_vlb_step=0.00012, train/loss_step=0.0339, global_step=96.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 98/20881 [09:53<34:57:25,  6.06s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0487, train/loss_vlb_step=0.000165, train/loss_step=0.0487, global_step=97.00]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 99/20881 [09:59<34:56:07,  6.05s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0188, train/loss_vlb_step=7.21e-5, train/loss_step=0.0188, global_step=98.00] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 100/20881 [10:04<34:53:17,  6.04s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0817, train/loss_vlb_step=0.00042, train/loss_step=0.0817, global_step=99.00]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 101/20881 [10:09<34:50:55,  6.04s/it, loss=0.103, v_num=0, train/loss_simple_step=0.197, train/loss_vlb_step=0.00109, train/loss_step=0.197, global_step=100.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 102/20881 [10:14<34:48:00,  6.03s/it, loss=0.109, v_num=0, train/loss_simple_step=0.199, train/loss_vlb_step=0.00492, train/loss_step=0.199, global_step=101.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 103/20881 [10:20<34:47:53,  6.03s/it, loss=0.101, v_num=0, train/loss_simple_step=0.0326, train/loss_vlb_step=0.000115, train/loss_step=0.0326, global_step=102.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 104/20881 [10:26<34:46:10,  6.02s/it, loss=0.0963, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000385, train/loss_step=0.104, global_step=103.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 105/20881 [10:31<34:42:03,  6.01s/it, loss=0.0947, v_num=0, train/loss_simple_step=0.115, train/loss_vlb_step=0.000429, train/loss_step=0.115, global_step=104.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 106/20881 [10:36<34:40:44,  6.01s/it, loss=0.0992, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000492, train/loss_step=0.104, global_step=105.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 107/20881 [10:42<34:39:08,  6.01s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0714, train/loss_vlb_step=0.000267, train/loss_step=0.0714, global_step=106.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 108/20881 [10:47<34:36:01,  6.00s/it, loss=0.0998, v_num=0, train/loss_simple_step=0.170, train/loss_vlb_step=0.000975, train/loss_step=0.170, global_step=107.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 109/20881 [10:53<34:35:04,  5.99s/it, loss=0.102, v_num=0, train/loss_simple_step=0.091, train/loss_vlb_step=0.000317, train/loss_step=0.091, global_step=108.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 110/20881 [10:58<34:32:16,  5.99s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0473, train/loss_vlb_step=0.000162, train/loss_step=0.0473, global_step=109.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 111/20881 [11:03<34:29:56,  5.98s/it, loss=0.108, v_num=0, train/loss_simple_step=0.161, train/loss_vlb_step=0.00408, train/loss_step=0.161, global_step=110.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 112/20881 [11:08<34:27:33,  5.97s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0769, train/loss_vlb_step=0.000259, train/loss_step=0.0769, global_step=111.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 113/20881 [11:13<34:24:12,  5.96s/it, loss=0.0956, v_num=0, train/loss_simple_step=0.0408, train/loss_vlb_step=0.000148, train/loss_step=0.0408, global_step=112.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 114/20881 [11:18<34:21:01,  5.95s/it, loss=0.0878, v_num=0, train/loss_simple_step=0.0521, train/loss_vlb_step=0.000178, train/loss_step=0.0521, global_step=113.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 115/20881 [11:24<34:19:04,  5.95s/it, loss=0.0873, v_num=0, train/loss_simple_step=0.0657, train/loss_vlb_step=0.00023, train/loss_step=0.0657, global_step=114.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 116/20881 [11:29<34:15:40,  5.94s/it, loss=0.0932, v_num=0, train/loss_simple_step=0.153, train/loss_vlb_step=0.000955, train/loss_step=0.153, global_step=115.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 117/20881 [11:34<34:13:32,  5.93s/it, loss=0.094, v_num=0, train/loss_simple_step=0.0497, train/loss_vlb_step=0.000172, train/loss_step=0.0497, global_step=116.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 118/20881 [11:39<34:11:05,  5.93s/it, loss=0.0939, v_num=0, train/loss_simple_step=0.0463, train/loss_vlb_step=0.000172, train/loss_step=0.0463, global_step=117.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 119/20881 [11:44<34:08:43,  5.92s/it, loss=0.108, v_num=0, train/loss_simple_step=0.307, train/loss_vlb_step=0.017, train/loss_step=0.307, global_step=118.0]      \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 120/20881 [11:50<34:09:07,  5.92s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0884, train/loss_vlb_step=0.000329, train/loss_step=0.0884, global_step=119.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 121/20881 [11:56<34:07:39,  5.92s/it, loss=0.116, v_num=0, train/loss_simple_step=0.353, train/loss_vlb_step=0.111, train/loss_step=0.353, global_step=120.0]     \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 122/20881 [12:01<34:06:38,  5.92s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0534, train/loss_vlb_step=0.000181, train/loss_step=0.0534, global_step=121.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 123/20881 [12:07<34:04:53,  5.91s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0655, train/loss_vlb_step=0.000307, train/loss_step=0.0655, global_step=122.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 124/20881 [12:12<34:04:16,  5.91s/it, loss=0.114, v_num=0, train/loss_simple_step=0.163, train/loss_vlb_step=0.00115, train/loss_step=0.163, global_step=123.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 125/20881 [12:17<34:02:10,  5.90s/it, loss=0.117, v_num=0, train/loss_simple_step=0.184, train/loss_vlb_step=0.00186, train/loss_step=0.184, global_step=124.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 126/20881 [12:23<34:02:17,  5.90s/it, loss=0.126, v_num=0, train/loss_simple_step=0.285, train/loss_vlb_step=0.0134, train/loss_step=0.285, global_step=125.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 127/20881 [12:30<34:03:48,  5.91s/it, loss=0.132, v_num=0, train/loss_simple_step=0.190, train/loss_vlb_step=0.000951, train/loss_step=0.190, global_step=126.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 128/20881 [12:35<34:00:54,  5.90s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0669, train/loss_vlb_step=0.000227, train/loss_step=0.0669, global_step=127.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 129/20881 [12:40<33:58:30,  5.89s/it, loss=0.133, v_num=0, train/loss_simple_step=0.217, train/loss_vlb_step=0.00473, train/loss_step=0.217, global_step=128.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 130/20881 [12:45<33:56:59,  5.89s/it, loss=0.132, v_num=0, train/loss_simple_step=0.018, train/loss_vlb_step=7.27e-5, train/loss_step=0.018, global_step=129.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 131/20881 [12:50<33:53:25,  5.88s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0604, train/loss_vlb_step=0.00021, train/loss_step=0.0604, global_step=130.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 132/20881 [12:54<33:49:36,  5.87s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0893, train/loss_vlb_step=0.000459, train/loss_step=0.0893, global_step=131.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 133/20881 [12:59<33:46:18,  5.86s/it, loss=0.129, v_num=0, train/loss_simple_step=0.0672, train/loss_vlb_step=0.000226, train/loss_step=0.0672, global_step=132.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 134/20881 [13:03<33:42:56,  5.85s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0177, train/loss_vlb_step=6.75e-5, train/loss_step=0.0177, global_step=133.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 135/20881 [13:08<33:40:05,  5.84s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0673, train/loss_vlb_step=0.000225, train/loss_step=0.0673, global_step=134.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 136/20881 [13:13<33:38:23,  5.84s/it, loss=0.123, v_num=0, train/loss_simple_step=0.0646, train/loss_vlb_step=0.000277, train/loss_step=0.0646, global_step=135.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 137/20881 [13:19<33:38:27,  5.84s/it, loss=0.122, v_num=0, train/loss_simple_step=0.0387, train/loss_vlb_step=0.000136, train/loss_step=0.0387, global_step=136.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 138/20881 [13:24<33:35:55,  5.83s/it, loss=0.132, v_num=0, train/loss_simple_step=0.243, train/loss_vlb_step=0.0135, train/loss_step=0.243, global_step=137.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 139/20881 [13:29<33:34:25,  5.83s/it, loss=0.122, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.000575, train/loss_step=0.105, global_step=138.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 140/20881 [13:34<33:32:14,  5.82s/it, loss=0.126, v_num=0, train/loss_simple_step=0.178, train/loss_vlb_step=0.00599, train/loss_step=0.178, global_step=139.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 141/20881 [13:40<33:30:19,  5.82s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0386, train/loss_vlb_step=0.000135, train/loss_step=0.0386, global_step=140.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 142/20881 [13:45<33:28:21,  5.81s/it, loss=0.113, v_num=0, train/loss_simple_step=0.107, train/loss_vlb_step=0.000477, train/loss_step=0.107, global_step=141.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 143/20881 [13:50<33:26:54,  5.81s/it, loss=0.115, v_num=0, train/loss_simple_step=0.096, train/loss_vlb_step=0.000529, train/loss_step=0.096, global_step=142.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 144/20881 [13:55<33:26:14,  5.80s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0411, train/loss_vlb_step=0.000148, train/loss_step=0.0411, global_step=143.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 145/20881 [14:01<33:25:31,  5.80s/it, loss=0.105, v_num=0, train/loss_simple_step=0.116, train/loss_vlb_step=0.000397, train/loss_step=0.116, global_step=144.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 146/20881 [14:06<33:24:31,  5.80s/it, loss=0.0924, v_num=0, train/loss_simple_step=0.0271, train/loss_vlb_step=9.69e-5, train/loss_step=0.0271, global_step=145.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 147/20881 [14:11<33:22:22,  5.79s/it, loss=0.0872, v_num=0, train/loss_simple_step=0.0853, train/loss_vlb_step=0.00037, train/loss_step=0.0853, global_step=146.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 148/20881 [14:16<33:19:32,  5.79s/it, loss=0.0884, v_num=0, train/loss_simple_step=0.0916, train/loss_vlb_step=0.000318, train/loss_step=0.0916, global_step=147.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 149/20881 [14:22<33:19:17,  5.79s/it, loss=0.0848, v_num=0, train/loss_simple_step=0.145, train/loss_vlb_step=0.00095, train/loss_step=0.145, global_step=148.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 150/20881 [14:28<33:20:01,  5.79s/it, loss=0.0871, v_num=0, train/loss_simple_step=0.0642, train/loss_vlb_step=0.000217, train/loss_step=0.0642, global_step=149.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 151/20881 [14:34<33:21:12,  5.79s/it, loss=0.0883, v_num=0, train/loss_simple_step=0.0832, train/loss_vlb_step=0.000312, train/loss_step=0.0832, global_step=150.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 152/20881 [14:39<33:19:36,  5.79s/it, loss=0.0859, v_num=0, train/loss_simple_step=0.0415, train/loss_vlb_step=0.000148, train/loss_step=0.0415, global_step=151.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 153/20881 [14:44<33:18:07,  5.78s/it, loss=0.0846, v_num=0, train/loss_simple_step=0.0422, train/loss_vlb_step=0.000147, train/loss_step=0.0422, global_step=152.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 154/20881 [14:49<33:15:16,  5.78s/it, loss=0.0882, v_num=0, train/loss_simple_step=0.0903, train/loss_vlb_step=0.00066, train/loss_step=0.0903, global_step=153.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 155/20881 [14:55<33:14:44,  5.77s/it, loss=0.0956, v_num=0, train/loss_simple_step=0.215, train/loss_vlb_step=0.0012, train/loss_step=0.215, global_step=154.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 156/20881 [15:00<33:13:32,  5.77s/it, loss=0.101, v_num=0, train/loss_simple_step=0.180, train/loss_vlb_step=0.000825, train/loss_step=0.180, global_step=155.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 157/20881 [15:06<33:13:20,  5.77s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0487, train/loss_vlb_step=0.000174, train/loss_step=0.0487, global_step=156.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 158/20881 [15:11<33:12:51,  5.77s/it, loss=0.0918, v_num=0, train/loss_simple_step=0.0406, train/loss_vlb_step=0.00014, train/loss_step=0.0406, global_step=157.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 159/20881 [15:16<33:11:15,  5.77s/it, loss=0.096, v_num=0, train/loss_simple_step=0.189, train/loss_vlb_step=0.0184, train/loss_step=0.189, global_step=158.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 160/20881 [15:21<33:08:17,  5.76s/it, loss=0.0942, v_num=0, train/loss_simple_step=0.141, train/loss_vlb_step=0.000937, train/loss_step=0.141, global_step=159.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 161/20881 [15:26<33:06:58,  5.75s/it, loss=0.0941, v_num=0, train/loss_simple_step=0.0369, train/loss_vlb_step=0.000129, train/loss_step=0.0369, global_step=160.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 162/20881 [15:30<33:04:26,  5.75s/it, loss=0.0981, v_num=0, train/loss_simple_step=0.187, train/loss_vlb_step=0.00187, train/loss_step=0.187, global_step=161.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 163/20881 [15:36<33:03:45,  5.75s/it, loss=0.107, v_num=0, train/loss_simple_step=0.276, train/loss_vlb_step=0.0339, train/loss_step=0.276, global_step=162.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 164/20881 [15:40<33:00:37,  5.74s/it, loss=0.115, v_num=0, train/loss_simple_step=0.193, train/loss_vlb_step=0.00116, train/loss_step=0.193, global_step=163.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 165/20881 [15:45<32:58:44,  5.73s/it, loss=0.118, v_num=0, train/loss_simple_step=0.175, train/loss_vlb_step=0.00114, train/loss_step=0.175, global_step=164.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 166/20881 [15:50<32:56:48,  5.73s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0916, train/loss_vlb_step=0.000357, train/loss_step=0.0916, global_step=165.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 167/20881 [15:54<32:53:07,  5.72s/it, loss=0.128, v_num=0, train/loss_simple_step=0.225, train/loss_vlb_step=0.00172, train/loss_step=0.225, global_step=166.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 168/20881 [15:58<32:49:58,  5.71s/it, loss=0.128, v_num=0, train/loss_simple_step=0.089, train/loss_vlb_step=0.000505, train/loss_step=0.089, global_step=167.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 169/20881 [16:02<32:46:42,  5.70s/it, loss=0.124, v_num=0, train/loss_simple_step=0.0745, train/loss_vlb_step=0.000367, train/loss_step=0.0745, global_step=168.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 170/20881 [16:07<32:45:27,  5.69s/it, loss=0.126, v_num=0, train/loss_simple_step=0.109, train/loss_vlb_step=0.000432, train/loss_step=0.109, global_step=169.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 171/20881 [16:13<32:45:06,  5.69s/it, loss=0.123, v_num=0, train/loss_simple_step=0.00944, train/loss_vlb_step=4.25e-5, train/loss_step=0.00944, global_step=170.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 172/20881 [16:18<32:43:58,  5.69s/it, loss=0.127, v_num=0, train/loss_simple_step=0.121, train/loss_vlb_step=0.000583, train/loss_step=0.121, global_step=171.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 173/20881 [16:23<32:42:29,  5.69s/it, loss=0.131, v_num=0, train/loss_simple_step=0.120, train/loss_vlb_step=0.000577, train/loss_step=0.120, global_step=172.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 174/20881 [16:28<32:41:23,  5.68s/it, loss=0.138, v_num=0, train/loss_simple_step=0.244, train/loss_vlb_step=0.0234, train/loss_step=0.244, global_step=173.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 175/20881 [16:33<32:38:53,  5.68s/it, loss=0.128, v_num=0, train/loss_simple_step=0.00701, train/loss_vlb_step=3.29e-5, train/loss_step=0.00701, global_step=174.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 176/20881 [16:37<32:36:43,  5.67s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0341, train/loss_vlb_step=0.000123, train/loss_step=0.0341, global_step=175.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 177/20881 [16:44<32:37:26,  5.67s/it, loss=0.129, v_num=0, train/loss_simple_step=0.225, train/loss_vlb_step=0.00245, train/loss_step=0.225, global_step=176.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 178/20881 [16:49<32:36:27,  5.67s/it, loss=0.137, v_num=0, train/loss_simple_step=0.188, train/loss_vlb_step=0.0017, train/loss_step=0.188, global_step=177.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 179/20881 [16:54<32:35:15,  5.67s/it, loss=0.133, v_num=0, train/loss_simple_step=0.110, train/loss_vlb_step=0.00055, train/loss_step=0.110, global_step=178.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 180/20881 [17:00<32:35:26,  5.67s/it, loss=0.134, v_num=0, train/loss_simple_step=0.166, train/loss_vlb_step=0.00085, train/loss_step=0.166, global_step=179.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 181/20881 [17:05<32:34:56,  5.67s/it, loss=0.133, v_num=0, train/loss_simple_step=0.0231, train/loss_vlb_step=8.55e-5, train/loss_step=0.0231, global_step=180.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 182/20881 [17:11<32:34:37,  5.67s/it, loss=0.126, v_num=0, train/loss_simple_step=0.0431, train/loss_vlb_step=0.000148, train/loss_step=0.0431, global_step=181.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 183/20881 [17:16<32:34:30,  5.67s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0944, train/loss_vlb_step=0.000359, train/loss_step=0.0944, global_step=182.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 184/20881 [17:22<32:34:51,  5.67s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0645, train/loss_vlb_step=0.000214, train/loss_step=0.0645, global_step=183.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 185/20881 [17:29<32:35:56,  5.67s/it, loss=0.11, v_num=0, train/loss_simple_step=0.163, train/loss_vlb_step=0.0013, train/loss_step=0.163, global_step=184.0]     \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 186/20881 [17:34<32:35:23,  5.67s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0218, train/loss_vlb_step=7.84e-5, train/loss_step=0.0218, global_step=185.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 187/20881 [17:39<32:34:39,  5.67s/it, loss=0.107, v_num=0, train/loss_simple_step=0.222, train/loss_vlb_step=0.00179, train/loss_step=0.222, global_step=186.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 188/20881 [17:45<32:33:48,  5.67s/it, loss=0.109, v_num=0, train/loss_simple_step=0.145, train/loss_vlb_step=0.00116, train/loss_step=0.145, global_step=187.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 189/20881 [17:50<32:32:30,  5.66s/it, loss=0.109, v_num=0, train/loss_simple_step=0.073, train/loss_vlb_step=0.000298, train/loss_step=0.073, global_step=188.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 190/20881 [17:55<32:32:20,  5.66s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0654, train/loss_vlb_step=0.000295, train/loss_step=0.0654, global_step=189.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 191/20881 [18:00<32:30:41,  5.66s/it, loss=0.109, v_num=0, train/loss_simple_step=0.047, train/loss_vlb_step=0.000167, train/loss_step=0.047, global_step=190.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 192/20881 [18:04<32:27:54,  5.65s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0766, train/loss_vlb_step=0.000286, train/loss_step=0.0766, global_step=191.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 193/20881 [18:09<32:25:56,  5.64s/it, loss=0.112, v_num=0, train/loss_simple_step=0.228, train/loss_vlb_step=0.00294, train/loss_step=0.228, global_step=192.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 194/20881 [18:14<32:24:18,  5.64s/it, loss=0.106, v_num=0, train/loss_simple_step=0.123, train/loss_vlb_step=0.000667, train/loss_step=0.123, global_step=193.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 195/20881 [18:19<32:23:26,  5.64s/it, loss=0.114, v_num=0, train/loss_simple_step=0.158, train/loss_vlb_step=0.00168, train/loss_step=0.158, global_step=194.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 196/20881 [18:24<32:22:27,  5.63s/it, loss=0.122, v_num=0, train/loss_simple_step=0.193, train/loss_vlb_step=0.0121, train/loss_step=0.193, global_step=195.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 197/20881 [18:29<32:22:09,  5.63s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0287, train/loss_vlb_step=0.000103, train/loss_step=0.0287, global_step=196.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 198/20881 [18:35<32:22:23,  5.63s/it, loss=0.107, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000381, train/loss_step=0.104, global_step=197.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 199/20881 [18:40<32:20:24,  5.63s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0852, train/loss_vlb_step=0.000622, train/loss_step=0.0852, global_step=198.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 200/20881 [18:45<32:20:21,  5.63s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0822, train/loss_vlb_step=0.000319, train/loss_step=0.0822, global_step=199.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 201/20881 [18:51<32:19:28,  5.63s/it, loss=0.109, v_num=0, train/loss_simple_step=0.171, train/loss_vlb_step=0.00151, train/loss_step=0.171, global_step=200.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 202/20881 [18:56<32:18:40,  5.63s/it, loss=0.118, v_num=0, train/loss_simple_step=0.213, train/loss_vlb_step=0.00114, train/loss_step=0.213, global_step=201.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 203/20881 [19:01<32:17:38,  5.62s/it, loss=0.12, v_num=0, train/loss_simple_step=0.129, train/loss_vlb_step=0.000564, train/loss_step=0.129, global_step=202.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 204/20881 [19:06<32:16:08,  5.62s/it, loss=0.125, v_num=0, train/loss_simple_step=0.167, train/loss_vlb_step=0.00157, train/loss_step=0.167, global_step=203.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 205/20881 [19:10<32:13:40,  5.61s/it, loss=0.118, v_num=0, train/loss_simple_step=0.0337, train/loss_vlb_step=0.000116, train/loss_step=0.0337, global_step=204.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 206/20881 [19:15<32:12:07,  5.61s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0693, train/loss_vlb_step=0.00028, train/loss_step=0.0693, global_step=205.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 207/20881 [19:20<32:10:55,  5.60s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0945, train/loss_vlb_step=0.000812, train/loss_step=0.0945, global_step=206.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 208/20881 [19:24<32:09:24,  5.60s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0853, train/loss_vlb_step=0.000386, train/loss_step=0.0853, global_step=207.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 209/20881 [19:30<32:09:07,  5.60s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0987, train/loss_vlb_step=0.000496, train/loss_step=0.0987, global_step=208.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 210/20881 [19:35<32:08:15,  5.60s/it, loss=0.116, v_num=0, train/loss_simple_step=0.137, train/loss_vlb_step=0.00112, train/loss_step=0.137, global_step=209.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 211/20881 [19:41<32:08:18,  5.60s/it, loss=0.122, v_num=0, train/loss_simple_step=0.171, train/loss_vlb_step=0.00135, train/loss_step=0.171, global_step=210.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 212/20881 [19:46<32:07:09,  5.59s/it, loss=0.129, v_num=0, train/loss_simple_step=0.215, train/loss_vlb_step=0.00224, train/loss_step=0.215, global_step=211.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 213/20881 [19:50<32:05:45,  5.59s/it, loss=0.124, v_num=0, train/loss_simple_step=0.130, train/loss_vlb_step=0.000687, train/loss_step=0.130, global_step=212.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 214/20881 [19:55<32:04:41,  5.59s/it, loss=0.12, v_num=0, train/loss_simple_step=0.0377, train/loss_vlb_step=0.000138, train/loss_step=0.0377, global_step=213.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 215/20881 [20:00<32:03:22,  5.58s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0882, train/loss_vlb_step=0.000309, train/loss_step=0.0882, global_step=214.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 216/20881 [20:05<32:01:34,  5.58s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0555, train/loss_vlb_step=0.000184, train/loss_step=0.0555, global_step=215.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 217/20881 [20:10<32:00:31,  5.58s/it, loss=0.118, v_num=0, train/loss_simple_step=0.198, train/loss_vlb_step=0.00273, train/loss_step=0.198, global_step=216.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 218/20881 [20:15<32:00:42,  5.58s/it, loss=0.125, v_num=0, train/loss_simple_step=0.230, train/loss_vlb_step=0.00234, train/loss_step=0.230, global_step=217.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 219/20881 [20:21<32:00:03,  5.58s/it, loss=0.131, v_num=0, train/loss_simple_step=0.213, train/loss_vlb_step=0.0016, train/loss_step=0.213, global_step=218.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 220/20881 [20:26<31:59:02,  5.57s/it, loss=0.138, v_num=0, train/loss_simple_step=0.227, train/loss_vlb_step=0.002, train/loss_step=0.227, global_step=219.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 221/20881 [20:30<31:57:05,  5.57s/it, loss=0.132, v_num=0, train/loss_simple_step=0.0475, train/loss_vlb_step=0.000187, train/loss_step=0.0475, global_step=220.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 222/20881 [20:35<31:56:06,  5.56s/it, loss=0.128, v_num=0, train/loss_simple_step=0.141, train/loss_vlb_step=0.00132, train/loss_step=0.141, global_step=221.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 223/20881 [20:40<31:55:45,  5.56s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0958, train/loss_vlb_step=0.000458, train/loss_step=0.0958, global_step=222.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 224/20881 [20:46<31:55:11,  5.56s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0182, train/loss_vlb_step=6.81e-5, train/loss_step=0.0182, global_step=223.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 225/20881 [20:51<31:54:32,  5.56s/it, loss=0.123, v_num=0, train/loss_simple_step=0.111, train/loss_vlb_step=0.000478, train/loss_step=0.111, global_step=224.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 226/20881 [20:56<31:53:21,  5.56s/it, loss=0.131, v_num=0, train/loss_simple_step=0.225, train/loss_vlb_step=0.00913, train/loss_step=0.225, global_step=225.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 227/20881 [21:00<31:51:06,  5.55s/it, loss=0.128, v_num=0, train/loss_simple_step=0.0386, train/loss_vlb_step=0.000139, train/loss_step=0.0386, global_step=226.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 228/20881 [21:05<31:50:17,  5.55s/it, loss=0.128, v_num=0, train/loss_simple_step=0.0782, train/loss_vlb_step=0.000284, train/loss_step=0.0782, global_step=227.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 229/20881 [21:10<31:49:27,  5.55s/it, loss=0.129, v_num=0, train/loss_simple_step=0.121, train/loss_vlb_step=0.000953, train/loss_step=0.121, global_step=228.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 230/20881 [21:15<31:49:13,  5.55s/it, loss=0.123, v_num=0, train/loss_simple_step=0.0222, train/loss_vlb_step=8.15e-5, train/loss_step=0.0222, global_step=229.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 231/20881 [21:21<31:49:23,  5.55s/it, loss=0.124, v_num=0, train/loss_simple_step=0.180, train/loss_vlb_step=0.00334, train/loss_step=0.180, global_step=230.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 232/20881 [21:26<31:48:11,  5.54s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0835, train/loss_vlb_step=0.000309, train/loss_step=0.0835, global_step=231.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 233/20881 [21:30<31:46:37,  5.54s/it, loss=0.118, v_num=0, train/loss_simple_step=0.142, train/loss_vlb_step=0.00191, train/loss_step=0.142, global_step=232.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 234/20881 [21:36<31:46:27,  5.54s/it, loss=0.124, v_num=0, train/loss_simple_step=0.156, train/loss_vlb_step=0.00329, train/loss_step=0.156, global_step=233.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 235/20881 [21:42<31:46:28,  5.54s/it, loss=0.13, v_num=0, train/loss_simple_step=0.214, train/loss_vlb_step=0.0041, train/loss_step=0.214, global_step=234.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 236/20881 [21:46<31:44:29,  5.53s/it, loss=0.128, v_num=0, train/loss_simple_step=0.0261, train/loss_vlb_step=9.22e-5, train/loss_step=0.0261, global_step=235.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 237/20881 [21:51<31:43:31,  5.53s/it, loss=0.129, v_num=0, train/loss_simple_step=0.209, train/loss_vlb_step=0.00135, train/loss_step=0.209, global_step=236.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 238/20881 [21:55<31:42:09,  5.53s/it, loss=0.127, v_num=0, train/loss_simple_step=0.187, train/loss_vlb_step=0.00332, train/loss_step=0.187, global_step=237.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 239/20881 [22:00<31:40:17,  5.52s/it, loss=0.127, v_num=0, train/loss_simple_step=0.225, train/loss_vlb_step=0.00192, train/loss_step=0.225, global_step=238.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 240/20881 [22:05<31:39:18,  5.52s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0172, train/loss_vlb_step=6.61e-5, train/loss_step=0.0172, global_step=239.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 241/20881 [22:09<31:37:33,  5.52s/it, loss=0.122, v_num=0, train/loss_simple_step=0.153, train/loss_vlb_step=0.00186, train/loss_step=0.153, global_step=240.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 242/20881 [22:13<31:35:09,  5.51s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0698, train/loss_vlb_step=0.000239, train/loss_step=0.0698, global_step=241.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 243/20881 [22:18<31:34:07,  5.51s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0718, train/loss_vlb_step=0.00024, train/loss_step=0.0718, global_step=242.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 244/20881 [22:23<31:33:13,  5.50s/it, loss=0.124, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.00143, train/loss_step=0.144, global_step=243.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 245/20881 [22:28<31:32:29,  5.50s/it, loss=0.125, v_num=0, train/loss_simple_step=0.130, train/loss_vlb_step=0.00115, train/loss_step=0.130, global_step=244.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 246/20881 [22:33<31:32:03,  5.50s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0473, train/loss_vlb_step=0.000167, train/loss_step=0.0473, global_step=245.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 247/20881 [22:38<31:31:04,  5.50s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0614, train/loss_vlb_step=0.000243, train/loss_step=0.0614, global_step=246.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 248/20881 [22:43<31:31:15,  5.50s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0509, train/loss_vlb_step=0.000175, train/loss_step=0.0509, global_step=247.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 249/20881 [22:49<31:31:34,  5.50s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0671, train/loss_vlb_step=0.000229, train/loss_step=0.0671, global_step=248.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 250/20881 [22:55<31:31:32,  5.50s/it, loss=0.118, v_num=0, train/loss_simple_step=0.113, train/loss_vlb_step=0.000618, train/loss_step=0.113, global_step=249.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 251/20881 [23:00<31:31:19,  5.50s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0841, train/loss_vlb_step=0.000452, train/loss_step=0.0841, global_step=250.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 252/20881 [23:05<31:30:52,  5.50s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0323, train/loss_vlb_step=0.000113, train/loss_step=0.0323, global_step=251.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 253/20881 [23:11<31:31:01,  5.50s/it, loss=0.109, v_num=0, train/loss_simple_step=0.116, train/loss_vlb_step=0.000444, train/loss_step=0.116, global_step=252.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 254/20881 [23:17<31:30:54,  5.50s/it, loss=0.103, v_num=0, train/loss_simple_step=0.0458, train/loss_vlb_step=0.000155, train/loss_step=0.0458, global_step=253.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 255/20881 [23:23<31:31:29,  5.50s/it, loss=0.104, v_num=0, train/loss_simple_step=0.232, train/loss_vlb_step=0.00158, train/loss_step=0.232, global_step=254.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 256/20881 [23:27<31:29:49,  5.50s/it, loss=0.119, v_num=0, train/loss_simple_step=0.326, train/loss_vlb_step=0.0029, train/loss_step=0.326, global_step=255.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 257/20881 [23:32<31:28:53,  5.50s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0137, train/loss_vlb_step=5.44e-5, train/loss_step=0.0137, global_step=256.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 258/20881 [23:38<31:30:02,  5.50s/it, loss=0.107, v_num=0, train/loss_simple_step=0.146, train/loss_vlb_step=0.00364, train/loss_step=0.146, global_step=257.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 259/20881 [23:42<31:28:11,  5.49s/it, loss=0.102, v_num=0, train/loss_simple_step=0.123, train/loss_vlb_step=0.000719, train/loss_step=0.123, global_step=258.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 260/20881 [23:47<31:27:05,  5.49s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0933, train/loss_vlb_step=0.000586, train/loss_step=0.0933, global_step=259.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 261/20881 [23:52<31:26:13,  5.49s/it, loss=0.106, v_num=0, train/loss_simple_step=0.146, train/loss_vlb_step=0.000611, train/loss_step=0.146, global_step=260.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 262/20881 [23:57<31:26:03,  5.49s/it, loss=0.105, v_num=0, train/loss_simple_step=0.053, train/loss_vlb_step=0.000183, train/loss_step=0.053, global_step=261.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 263/20881 [24:02<31:25:16,  5.49s/it, loss=0.103, v_num=0, train/loss_simple_step=0.0454, train/loss_vlb_step=0.000155, train/loss_step=0.0454, global_step=262.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 264/20881 [24:07<31:24:37,  5.48s/it, loss=0.101, v_num=0, train/loss_simple_step=0.0878, train/loss_vlb_step=0.000321, train/loss_step=0.0878, global_step=263.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 265/20881 [24:13<31:24:10,  5.48s/it, loss=0.0981, v_num=0, train/loss_simple_step=0.0778, train/loss_vlb_step=0.000279, train/loss_step=0.0778, global_step=264.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 266/20881 [24:18<31:24:29,  5.48s/it, loss=0.0976, v_num=0, train/loss_simple_step=0.0382, train/loss_vlb_step=0.000136, train/loss_step=0.0382, global_step=265.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 267/20881 [24:24<31:23:54,  5.48s/it, loss=0.102, v_num=0, train/loss_simple_step=0.148, train/loss_vlb_step=0.000648, train/loss_step=0.148, global_step=266.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 268/20881 [24:29<31:23:47,  5.48s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0474, train/loss_vlb_step=0.000188, train/loss_step=0.0474, global_step=267.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 269/20881 [24:35<31:23:48,  5.48s/it, loss=0.105, v_num=0, train/loss_simple_step=0.129, train/loss_vlb_step=0.000598, train/loss_step=0.129, global_step=268.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 270/20881 [24:40<31:23:26,  5.48s/it, loss=0.106, v_num=0, train/loss_simple_step=0.130, train/loss_vlb_step=0.00075, train/loss_step=0.130, global_step=269.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 271/20881 [24:45<31:22:42,  5.48s/it, loss=0.104, v_num=0, train/loss_simple_step=0.0457, train/loss_vlb_step=0.000176, train/loss_step=0.0457, global_step=270.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 272/20881 [24:50<31:22:40,  5.48s/it, loss=0.108, v_num=0, train/loss_simple_step=0.116, train/loss_vlb_step=0.000619, train/loss_step=0.116, global_step=271.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 273/20881 [24:56<31:22:40,  5.48s/it, loss=0.114, v_num=0, train/loss_simple_step=0.232, train/loss_vlb_step=0.00137, train/loss_step=0.232, global_step=272.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 274/20881 [25:01<31:21:29,  5.48s/it, loss=0.117, v_num=0, train/loss_simple_step=0.112, train/loss_vlb_step=0.000927, train/loss_step=0.112, global_step=273.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 275/20881 [25:06<31:21:21,  5.48s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0132, train/loss_vlb_step=5.2e-5, train/loss_step=0.0132, global_step=274.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 276/20881 [25:10<31:19:54,  5.47s/it, loss=0.103, v_num=0, train/loss_simple_step=0.269, train/loss_vlb_step=0.00272, train/loss_step=0.269, global_step=275.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 277/20881 [25:15<31:19:06,  5.47s/it, loss=0.109, v_num=0, train/loss_simple_step=0.125, train/loss_vlb_step=0.000791, train/loss_step=0.125, global_step=276.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 278/20881 [25:21<31:18:50,  5.47s/it, loss=0.109, v_num=0, train/loss_simple_step=0.150, train/loss_vlb_step=0.00148, train/loss_step=0.150, global_step=277.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 279/20881 [25:26<31:18:17,  5.47s/it, loss=0.104, v_num=0, train/loss_simple_step=0.0297, train/loss_vlb_step=0.000107, train/loss_step=0.0297, global_step=278.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 280/20881 [25:30<31:16:14,  5.46s/it, loss=0.107, v_num=0, train/loss_simple_step=0.152, train/loss_vlb_step=0.00323, train/loss_step=0.152, global_step=279.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 281/20881 [25:35<31:15:47,  5.46s/it, loss=0.101, v_num=0, train/loss_simple_step=0.0268, train/loss_vlb_step=9.89e-5, train/loss_step=0.0268, global_step=280.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 282/20881 [25:39<31:14:42,  5.46s/it, loss=0.104, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.000363, train/loss_step=0.105, global_step=281.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 283/20881 [25:44<31:14:10,  5.46s/it, loss=0.103, v_num=0, train/loss_simple_step=0.025, train/loss_vlb_step=8.75e-5, train/loss_step=0.025, global_step=282.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 284/20881 [25:49<31:13:21,  5.46s/it, loss=0.106, v_num=0, train/loss_simple_step=0.149, train/loss_vlb_step=0.00146, train/loss_step=0.149, global_step=283.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 285/20881 [25:54<31:12:30,  5.45s/it, loss=0.107, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.000689, train/loss_step=0.105, global_step=284.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 286/20881 [25:59<31:11:12,  5.45s/it, loss=0.108, v_num=0, train/loss_simple_step=0.0546, train/loss_vlb_step=0.000225, train/loss_step=0.0546, global_step=285.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 287/20881 [26:04<31:10:34,  5.45s/it, loss=0.106, v_num=0, train/loss_simple_step=0.114, train/loss_vlb_step=0.000468, train/loss_step=0.114, global_step=286.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 288/20881 [26:08<31:09:25,  5.45s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0319, train/loss_vlb_step=0.000114, train/loss_step=0.0319, global_step=287.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 289/20881 [26:13<31:08:39,  5.44s/it, loss=0.111, v_num=0, train/loss_simple_step=0.236, train/loss_vlb_step=0.00201, train/loss_step=0.236, global_step=288.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 290/20881 [26:18<31:08:08,  5.44s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0409, train/loss_vlb_step=0.000153, train/loss_step=0.0409, global_step=289.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 291/20881 [26:22<31:06:39,  5.44s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0394, train/loss_vlb_step=0.000137, train/loss_step=0.0394, global_step=290.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 292/20881 [26:27<31:05:02,  5.44s/it, loss=0.111, v_num=0, train/loss_simple_step=0.202, train/loss_vlb_step=0.0314, train/loss_step=0.202, global_step=291.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 293/20881 [26:31<31:03:48,  5.43s/it, loss=0.11, v_num=0, train/loss_simple_step=0.228, train/loss_vlb_step=0.00334, train/loss_step=0.228, global_step=292.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 294/20881 [26:37<31:04:33,  5.43s/it, loss=0.112, v_num=0, train/loss_simple_step=0.139, train/loss_vlb_step=0.00102, train/loss_step=0.139, global_step=293.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 295/20881 [26:43<31:04:58,  5.44s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0995, train/loss_vlb_step=0.000383, train/loss_step=0.0995, global_step=294.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 296/20881 [26:48<31:04:26,  5.43s/it, loss=0.108, v_num=0, train/loss_simple_step=0.0976, train/loss_vlb_step=0.00035, train/loss_step=0.0976, global_step=295.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 297/20881 [26:54<31:04:42,  5.44s/it, loss=0.107, v_num=0, train/loss_simple_step=0.108, train/loss_vlb_step=0.000546, train/loss_step=0.108, global_step=296.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 298/20881 [27:00<31:05:30,  5.44s/it, loss=0.112, v_num=0, train/loss_simple_step=0.264, train/loss_vlb_step=0.0514, train/loss_step=0.264, global_step=297.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 299/20881 [27:05<31:05:08,  5.44s/it, loss=0.117, v_num=0, train/loss_simple_step=0.121, train/loss_vlb_step=0.000593, train/loss_step=0.121, global_step=298.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 300/20881 [27:11<31:05:02,  5.44s/it, loss=0.11, v_num=0, train/loss_simple_step=0.00989, train/loss_vlb_step=4.29e-5, train/loss_step=0.00989, global_step=299.0]\n",
      "\n",
      "\n",
      "\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▏         | 1/50 [00:00<00:22,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:   4%|▍         | 2/50 [00:00<00:21,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:   6%|▌         | 3/50 [00:01<00:21,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:   8%|▊         | 4/50 [00:01<00:20,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  10%|█         | 5/50 [00:02<00:20,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  12%|█▏        | 6/50 [00:02<00:19,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  14%|█▍        | 7/50 [00:03<00:19,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  16%|█▌        | 8/50 [00:03<00:19,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█▊        | 9/50 [00:04<00:18,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  20%|██        | 10/50 [00:04<00:18,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██▏       | 11/50 [00:04<00:17,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██▍       | 12/50 [00:05<00:17,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  26%|██▌       | 13/50 [00:05<00:16,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  28%|██▊       | 14/50 [00:06<00:16,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  30%|███       | 15/50 [00:06<00:15,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  32%|███▏      | 16/50 [00:07<00:15,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  34%|███▍      | 17/50 [00:07<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  36%|███▌      | 18/50 [00:08<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███▊      | 19/50 [00:08<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  40%|████      | 20/50 [00:09<00:13,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████▏     | 21/50 [00:09<00:13,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████▍     | 22/50 [00:09<00:12,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  46%|████▌     | 23/50 [00:10<00:12,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  48%|████▊     | 24/50 [00:10<00:11,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  50%|█████     | 25/50 [00:11<00:11,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  52%|█████▏    | 26/50 [00:11<00:10,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  54%|█████▍    | 27/50 [00:12<00:10,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  56%|█████▌    | 28/50 [00:12<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  58%|█████▊    | 29/50 [00:13<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  60%|██████    | 30/50 [00:13<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  62%|██████▏   | 31/50 [00:14<00:08,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████▍   | 32/50 [00:14<00:08,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  66%|██████▌   | 33/50 [00:14<00:07,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  68%|██████▊   | 34/50 [00:15<00:07,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  70%|███████   | 35/50 [00:15<00:06,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  72%|███████▏  | 36/50 [00:16<00:06,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  74%|███████▍  | 37/50 [00:16<00:05,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  76%|███████▌  | 38/50 [00:17<00:05,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  78%|███████▊  | 39/50 [00:17<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  80%|████████  | 40/50 [00:18<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  82%|████████▏ | 41/50 [00:18<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████▍ | 42/50 [00:19<00:03,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████▌ | 43/50 [00:19<00:03,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  88%|████████▊ | 44/50 [00:19<00:02,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  90%|█████████ | 45/50 [00:20<00:02,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  92%|█████████▏| 46/50 [00:20<00:01,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  94%|█████████▍| 47/50 [00:21<00:01,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  96%|█████████▌| 48/50 [00:21<00:00,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  98%|█████████▊| 49/50 [00:22<00:00,  2.21it/s]\u001b[A\n",
      "DDIM Sampler: 100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|▏         | 301/20881 [27:45<31:37:30,  5.53s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0832, train/loss_vlb_step=0.000466, train/loss_step=0.0832, global_step=300.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 302/20881 [27:48<31:35:22,  5.53s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0803, train/loss_vlb_step=0.000326, train/loss_step=0.0803, global_step=301.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 303/20881 [27:53<31:34:29,  5.52s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0735, train/loss_vlb_step=0.000259, train/loss_step=0.0735, global_step=302.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 304/20881 [27:59<31:34:29,  5.52s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0923, train/loss_vlb_step=0.000327, train/loss_step=0.0923, global_step=303.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 305/20881 [28:03<31:33:02,  5.52s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0648, train/loss_vlb_step=0.000221, train/loss_step=0.0648, global_step=304.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 306/20881 [28:08<31:32:05,  5.52s/it, loss=0.111, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000397, train/loss_step=0.104, global_step=305.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 307/20881 [28:12<31:30:28,  5.51s/it, loss=0.113, v_num=0, train/loss_simple_step=0.148, train/loss_vlb_step=0.000952, train/loss_step=0.148, global_step=306.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 308/20881 [28:17<31:29:48,  5.51s/it, loss=0.117, v_num=0, train/loss_simple_step=0.110, train/loss_vlb_step=0.000506, train/loss_step=0.110, global_step=307.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 309/20881 [28:23<31:30:32,  5.51s/it, loss=0.111, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.00038, train/loss_step=0.105, global_step=308.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 310/20881 [28:28<31:29:56,  5.51s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0736, train/loss_vlb_step=0.000311, train/loss_step=0.0736, global_step=309.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 311/20881 [28:33<31:29:00,  5.51s/it, loss=0.116, v_num=0, train/loss_simple_step=0.111, train/loss_vlb_step=0.000505, train/loss_step=0.111, global_step=310.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 312/20881 [28:37<31:27:27,  5.51s/it, loss=0.111, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.000472, train/loss_step=0.105, global_step=311.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   1%|▏         | 313/20881 [28:42<31:26:28,  5.50s/it, loss=0.103, v_num=0, train/loss_simple_step=0.0764, train/loss_vlb_step=0.000489, train/loss_step=0.0764, global_step=312.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 314/20881 [28:48<31:26:32,  5.50s/it, loss=0.102, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000392, train/loss_step=0.104, global_step=313.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 315/20881 [28:53<31:26:06,  5.50s/it, loss=0.097, v_num=0, train/loss_simple_step=0.00908, train/loss_vlb_step=3.92e-5, train/loss_step=0.00908, global_step=314.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 316/20881 [28:58<31:25:34,  5.50s/it, loss=0.0987, v_num=0, train/loss_simple_step=0.131, train/loss_vlb_step=0.000624, train/loss_step=0.131, global_step=315.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 317/20881 [29:03<31:25:08,  5.50s/it, loss=0.0966, v_num=0, train/loss_simple_step=0.0657, train/loss_vlb_step=0.000232, train/loss_step=0.0657, global_step=316.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 318/20881 [29:09<31:25:35,  5.50s/it, loss=0.09, v_num=0, train/loss_simple_step=0.132, train/loss_vlb_step=0.000624, train/loss_step=0.132, global_step=317.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 319/20881 [29:13<31:24:06,  5.50s/it, loss=0.0891, v_num=0, train/loss_simple_step=0.103, train/loss_vlb_step=0.000547, train/loss_step=0.103, global_step=318.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 320/20881 [29:19<31:24:03,  5.50s/it, loss=0.0942, v_num=0, train/loss_simple_step=0.112, train/loss_vlb_step=0.00041, train/loss_step=0.112, global_step=319.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 321/20881 [29:24<31:23:05,  5.50s/it, loss=0.0999, v_num=0, train/loss_simple_step=0.197, train/loss_vlb_step=0.0017, train/loss_step=0.197, global_step=320.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 322/20881 [29:28<31:22:02,  5.49s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0886, train/loss_vlb_step=0.000677, train/loss_step=0.0886, global_step=321.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 323/20881 [29:34<31:22:15,  5.49s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0735, train/loss_vlb_step=0.000242, train/loss_step=0.0735, global_step=322.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 324/20881 [29:39<31:21:56,  5.49s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0888, train/loss_vlb_step=0.000351, train/loss_step=0.0888, global_step=323.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 325/20881 [29:44<31:21:17,  5.49s/it, loss=0.0997, v_num=0, train/loss_simple_step=0.055, train/loss_vlb_step=0.000203, train/loss_step=0.055, global_step=324.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 326/20881 [29:50<31:21:29,  5.49s/it, loss=0.0958, v_num=0, train/loss_simple_step=0.0276, train/loss_vlb_step=9.77e-5, train/loss_step=0.0276, global_step=325.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 327/20881 [29:55<31:20:48,  5.49s/it, loss=0.0899, v_num=0, train/loss_simple_step=0.0292, train/loss_vlb_step=0.000102, train/loss_step=0.0292, global_step=326.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 328/20881 [30:00<31:20:45,  5.49s/it, loss=0.0913, v_num=0, train/loss_simple_step=0.139, train/loss_vlb_step=0.000792, train/loss_step=0.139, global_step=327.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 329/20881 [30:06<31:20:46,  5.49s/it, loss=0.096, v_num=0, train/loss_simple_step=0.198, train/loss_vlb_step=0.00114, train/loss_step=0.198, global_step=328.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 330/20881 [30:11<31:20:32,  5.49s/it, loss=0.0997, v_num=0, train/loss_simple_step=0.149, train/loss_vlb_step=0.00145, train/loss_step=0.149, global_step=329.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 331/20881 [30:17<31:20:50,  5.49s/it, loss=0.0995, v_num=0, train/loss_simple_step=0.106, train/loss_vlb_step=0.000852, train/loss_step=0.106, global_step=330.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 332/20881 [30:22<31:19:41,  5.49s/it, loss=0.0963, v_num=0, train/loss_simple_step=0.0409, train/loss_vlb_step=0.000145, train/loss_step=0.0409, global_step=331.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 333/20881 [30:27<31:19:13,  5.49s/it, loss=0.0956, v_num=0, train/loss_simple_step=0.0623, train/loss_vlb_step=0.00026, train/loss_step=0.0623, global_step=332.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 334/20881 [30:32<31:18:42,  5.49s/it, loss=0.0959, v_num=0, train/loss_simple_step=0.111, train/loss_vlb_step=0.000476, train/loss_step=0.111, global_step=333.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 335/20881 [30:38<31:19:05,  5.49s/it, loss=0.105, v_num=0, train/loss_simple_step=0.185, train/loss_vlb_step=0.00179, train/loss_step=0.185, global_step=334.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 336/20881 [30:42<31:17:32,  5.48s/it, loss=0.103, v_num=0, train/loss_simple_step=0.0866, train/loss_vlb_step=0.000342, train/loss_step=0.0866, global_step=335.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 337/20881 [30:46<31:15:58,  5.48s/it, loss=0.104, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000468, train/loss_step=0.104, global_step=336.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 338/20881 [30:51<31:15:05,  5.48s/it, loss=0.103, v_num=0, train/loss_simple_step=0.0934, train/loss_vlb_step=0.000406, train/loss_step=0.0934, global_step=337.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 339/20881 [30:56<31:15:04,  5.48s/it, loss=0.103, v_num=0, train/loss_simple_step=0.110, train/loss_vlb_step=0.00103, train/loss_step=0.110, global_step=338.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 340/20881 [31:01<31:14:00,  5.47s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0577, train/loss_vlb_step=0.000198, train/loss_step=0.0577, global_step=339.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 341/20881 [31:07<31:14:41,  5.48s/it, loss=0.0972, v_num=0, train/loss_simple_step=0.138, train/loss_vlb_step=0.00123, train/loss_step=0.138, global_step=340.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 342/20881 [31:13<31:15:38,  5.48s/it, loss=0.0978, v_num=0, train/loss_simple_step=0.0999, train/loss_vlb_step=0.000626, train/loss_step=0.0999, global_step=341.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 343/20881 [31:18<31:14:47,  5.48s/it, loss=0.103, v_num=0, train/loss_simple_step=0.185, train/loss_vlb_step=0.00171, train/loss_step=0.185, global_step=342.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 344/20881 [31:24<31:14:49,  5.48s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0513, train/loss_vlb_step=0.000172, train/loss_step=0.0513, global_step=343.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 345/20881 [31:29<31:14:26,  5.48s/it, loss=0.11, v_num=0, train/loss_simple_step=0.224, train/loss_vlb_step=0.00291, train/loss_step=0.224, global_step=344.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 346/20881 [31:35<31:14:30,  5.48s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0762, train/loss_vlb_step=0.000268, train/loss_step=0.0762, global_step=345.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 347/20881 [31:40<31:14:33,  5.48s/it, loss=0.115, v_num=0, train/loss_simple_step=0.0835, train/loss_vlb_step=0.000367, train/loss_step=0.0835, global_step=346.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 348/20881 [31:46<31:14:47,  5.48s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0737, train/loss_vlb_step=0.000266, train/loss_step=0.0737, global_step=347.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 349/20881 [31:52<31:14:51,  5.48s/it, loss=0.103, v_num=0, train/loss_simple_step=0.0226, train/loss_vlb_step=8.38e-5, train/loss_step=0.0226, global_step=348.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 350/20881 [31:57<31:14:40,  5.48s/it, loss=0.0989, v_num=0, train/loss_simple_step=0.0655, train/loss_vlb_step=0.000338, train/loss_step=0.0655, global_step=349.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 351/20881 [32:03<31:14:56,  5.48s/it, loss=0.1, v_num=0, train/loss_simple_step=0.134, train/loss_vlb_step=0.000677, train/loss_step=0.134, global_step=350.0]     \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 352/20881 [32:08<31:14:20,  5.48s/it, loss=0.104, v_num=0, train/loss_simple_step=0.108, train/loss_vlb_step=0.000514, train/loss_step=0.108, global_step=351.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 353/20881 [32:13<31:14:21,  5.48s/it, loss=0.109, v_num=0, train/loss_simple_step=0.166, train/loss_vlb_step=0.00607, train/loss_step=0.166, global_step=352.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 354/20881 [32:20<31:14:54,  5.48s/it, loss=0.119, v_num=0, train/loss_simple_step=0.305, train/loss_vlb_step=0.0117, train/loss_step=0.305, global_step=353.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 355/20881 [32:24<31:14:04,  5.48s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0653, train/loss_vlb_step=0.000262, train/loss_step=0.0653, global_step=354.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 356/20881 [32:31<31:15:12,  5.48s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0568, train/loss_vlb_step=0.000191, train/loss_step=0.0568, global_step=355.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 357/20881 [32:37<31:15:08,  5.48s/it, loss=0.111, v_num=0, train/loss_simple_step=0.101, train/loss_vlb_step=0.000376, train/loss_step=0.101, global_step=356.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 358/20881 [32:43<31:15:58,  5.48s/it, loss=0.113, v_num=0, train/loss_simple_step=0.140, train/loss_vlb_step=0.00126, train/loss_step=0.140, global_step=357.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 359/20881 [32:48<31:15:36,  5.48s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0879, train/loss_vlb_step=0.00043, train/loss_step=0.0879, global_step=358.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 360/20881 [32:54<31:15:39,  5.48s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0892, train/loss_vlb_step=0.000325, train/loss_step=0.0892, global_step=359.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 361/20881 [33:00<31:16:09,  5.49s/it, loss=0.112, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.00038, train/loss_step=0.104, global_step=360.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 362/20881 [33:05<31:15:15,  5.48s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0902, train/loss_vlb_step=0.000379, train/loss_step=0.0902, global_step=361.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 363/20881 [33:10<31:14:44,  5.48s/it, loss=0.114, v_num=0, train/loss_simple_step=0.227, train/loss_vlb_step=0.00367, train/loss_step=0.227, global_step=362.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 364/20881 [33:16<31:15:26,  5.48s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0919, train/loss_vlb_step=0.000645, train/loss_step=0.0919, global_step=363.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 365/20881 [33:21<31:15:28,  5.48s/it, loss=0.111, v_num=0, train/loss_simple_step=0.134, train/loss_vlb_step=0.000677, train/loss_step=0.134, global_step=364.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 366/20881 [33:26<31:14:49,  5.48s/it, loss=0.108, v_num=0, train/loss_simple_step=0.00436, train/loss_vlb_step=2.2e-5, train/loss_step=0.00436, global_step=365.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 367/20881 [33:33<31:15:29,  5.49s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0629, train/loss_vlb_step=0.000217, train/loss_step=0.0629, global_step=366.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 368/20881 [33:38<31:15:21,  5.49s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0899, train/loss_vlb_step=0.000341, train/loss_step=0.0899, global_step=367.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 369/20881 [33:43<31:14:31,  5.48s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0622, train/loss_vlb_step=0.000236, train/loss_step=0.0622, global_step=368.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 370/20881 [33:48<31:14:09,  5.48s/it, loss=0.112, v_num=0, train/loss_simple_step=0.120, train/loss_vlb_step=0.000426, train/loss_step=0.120, global_step=369.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 371/20881 [33:53<31:13:13,  5.48s/it, loss=0.116, v_num=0, train/loss_simple_step=0.214, train/loss_vlb_step=0.00172, train/loss_step=0.214, global_step=370.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 372/20881 [33:58<31:13:20,  5.48s/it, loss=0.115, v_num=0, train/loss_simple_step=0.0919, train/loss_vlb_step=0.000513, train/loss_step=0.0919, global_step=371.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 373/20881 [34:03<31:12:14,  5.48s/it, loss=0.113, v_num=0, train/loss_simple_step=0.112, train/loss_vlb_step=0.000453, train/loss_step=0.112, global_step=372.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 374/20881 [34:07<31:10:54,  5.47s/it, loss=0.0997, v_num=0, train/loss_simple_step=0.0493, train/loss_vlb_step=0.000175, train/loss_step=0.0493, global_step=373.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 375/20881 [34:12<31:10:09,  5.47s/it, loss=0.104, v_num=0, train/loss_simple_step=0.152, train/loss_vlb_step=0.00328, train/loss_step=0.152, global_step=374.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 376/20881 [34:17<31:10:23,  5.47s/it, loss=0.111, v_num=0, train/loss_simple_step=0.199, train/loss_vlb_step=0.00334, train/loss_step=0.199, global_step=375.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 377/20881 [34:23<31:10:43,  5.47s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0581, train/loss_vlb_step=0.00021, train/loss_step=0.0581, global_step=376.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 378/20881 [34:28<31:10:04,  5.47s/it, loss=0.108, v_num=0, train/loss_simple_step=0.110, train/loss_vlb_step=0.000523, train/loss_step=0.110, global_step=377.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 379/20881 [34:33<31:09:23,  5.47s/it, loss=0.105, v_num=0, train/loss_simple_step=0.0462, train/loss_vlb_step=0.000155, train/loss_step=0.0462, global_step=378.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 380/20881 [34:37<31:08:11,  5.47s/it, loss=0.109, v_num=0, train/loss_simple_step=0.158, train/loss_vlb_step=0.00392, train/loss_step=0.158, global_step=379.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 381/20881 [34:42<31:07:31,  5.47s/it, loss=0.11, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.000689, train/loss_step=0.124, global_step=380.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 382/20881 [34:46<31:06:32,  5.46s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0845, train/loss_vlb_step=0.000402, train/loss_step=0.0845, global_step=381.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 383/20881 [34:51<31:05:46,  5.46s/it, loss=0.104, v_num=0, train/loss_simple_step=0.109, train/loss_vlb_step=0.000603, train/loss_step=0.109, global_step=382.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 384/20881 [34:56<31:05:24,  5.46s/it, loss=0.108, v_num=0, train/loss_simple_step=0.178, train/loss_vlb_step=0.00172, train/loss_step=0.178, global_step=383.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 385/20881 [35:02<31:05:18,  5.46s/it, loss=0.106, v_num=0, train/loss_simple_step=0.091, train/loss_vlb_step=0.000337, train/loss_step=0.091, global_step=384.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 386/20881 [35:09<31:06:24,  5.46s/it, loss=0.117, v_num=0, train/loss_simple_step=0.226, train/loss_vlb_step=0.00952, train/loss_step=0.226, global_step=385.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 387/20881 [35:14<31:06:35,  5.46s/it, loss=0.117, v_num=0, train/loss_simple_step=0.066, train/loss_vlb_step=0.000238, train/loss_step=0.066, global_step=386.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 388/20881 [35:20<31:06:30,  5.46s/it, loss=0.122, v_num=0, train/loss_simple_step=0.183, train/loss_vlb_step=0.00422, train/loss_step=0.183, global_step=387.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 389/20881 [35:27<31:07:33,  5.47s/it, loss=0.124, v_num=0, train/loss_simple_step=0.106, train/loss_vlb_step=0.000504, train/loss_step=0.106, global_step=388.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 390/20881 [35:32<31:07:25,  5.47s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0199, train/loss_vlb_step=7.35e-5, train/loss_step=0.0199, global_step=389.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 391/20881 [35:39<31:08:20,  5.47s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0477, train/loss_vlb_step=0.000165, train/loss_step=0.0477, global_step=390.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 392/20881 [35:44<31:07:59,  5.47s/it, loss=0.121, v_num=0, train/loss_simple_step=0.294, train/loss_vlb_step=0.104, train/loss_step=0.294, global_step=391.0]     \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 393/20881 [35:50<31:08:11,  5.47s/it, loss=0.123, v_num=0, train/loss_simple_step=0.169, train/loss_vlb_step=0.00131, train/loss_step=0.169, global_step=392.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 394/20881 [35:55<31:07:53,  5.47s/it, loss=0.126, v_num=0, train/loss_simple_step=0.108, train/loss_vlb_step=0.00048, train/loss_step=0.108, global_step=393.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 395/20881 [36:00<31:07:42,  5.47s/it, loss=0.132, v_num=0, train/loss_simple_step=0.260, train/loss_vlb_step=0.0252, train/loss_step=0.260, global_step=394.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 396/20881 [36:05<31:07:18,  5.47s/it, loss=0.125, v_num=0, train/loss_simple_step=0.0589, train/loss_vlb_step=0.000216, train/loss_step=0.0589, global_step=395.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 397/20881 [36:11<31:07:31,  5.47s/it, loss=0.124, v_num=0, train/loss_simple_step=0.0505, train/loss_vlb_step=0.000189, train/loss_step=0.0505, global_step=396.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 398/20881 [36:16<31:07:03,  5.47s/it, loss=0.12, v_num=0, train/loss_simple_step=0.0124, train/loss_vlb_step=4.67e-5, train/loss_step=0.0124, global_step=397.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 399/20881 [36:22<31:07:36,  5.47s/it, loss=0.123, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.00144, train/loss_step=0.124, global_step=398.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 400/20881 [36:28<31:07:13,  5.47s/it, loss=0.123, v_num=0, train/loss_simple_step=0.140, train/loss_vlb_step=0.000644, train/loss_step=0.140, global_step=399.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 401/20881 [36:33<31:06:43,  5.47s/it, loss=0.126, v_num=0, train/loss_simple_step=0.199, train/loss_vlb_step=0.00216, train/loss_step=0.199, global_step=400.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 402/20881 [36:38<31:06:59,  5.47s/it, loss=0.125, v_num=0, train/loss_simple_step=0.0693, train/loss_vlb_step=0.000385, train/loss_step=0.0693, global_step=401.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 403/20881 [36:44<31:07:13,  5.47s/it, loss=0.125, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.000529, train/loss_step=0.105, global_step=402.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 404/20881 [36:49<31:06:26,  5.47s/it, loss=0.12, v_num=0, train/loss_simple_step=0.0665, train/loss_vlb_step=0.000245, train/loss_step=0.0665, global_step=403.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 405/20881 [36:54<31:06:16,  5.47s/it, loss=0.121, v_num=0, train/loss_simple_step=0.106, train/loss_vlb_step=0.000558, train/loss_step=0.106, global_step=404.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 406/20881 [36:59<31:05:48,  5.47s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0289, train/loss_vlb_step=0.000104, train/loss_step=0.0289, global_step=405.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 407/20881 [37:05<31:05:35,  5.47s/it, loss=0.113, v_num=0, train/loss_simple_step=0.109, train/loss_vlb_step=0.000517, train/loss_step=0.109, global_step=406.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 408/20881 [37:10<31:05:01,  5.47s/it, loss=0.113, v_num=0, train/loss_simple_step=0.195, train/loss_vlb_step=0.00216, train/loss_step=0.195, global_step=407.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 409/20881 [37:14<31:04:28,  5.46s/it, loss=0.111, v_num=0, train/loss_simple_step=0.050, train/loss_vlb_step=0.000187, train/loss_step=0.050, global_step=408.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 410/20881 [37:19<31:03:34,  5.46s/it, loss=0.117, v_num=0, train/loss_simple_step=0.140, train/loss_vlb_step=0.00314, train/loss_step=0.140, global_step=409.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 411/20881 [37:25<31:03:49,  5.46s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0308, train/loss_vlb_step=0.000107, train/loss_step=0.0308, global_step=410.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 412/20881 [37:31<31:04:39,  5.47s/it, loss=0.107, v_num=0, train/loss_simple_step=0.112, train/loss_vlb_step=0.000617, train/loss_step=0.112, global_step=411.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 413/20881 [37:37<31:04:23,  5.47s/it, loss=0.0987, v_num=0, train/loss_simple_step=0.00962, train/loss_vlb_step=4.27e-5, train/loss_step=0.00962, global_step=412.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 414/20881 [37:43<31:04:40,  5.47s/it, loss=0.0985, v_num=0, train/loss_simple_step=0.103, train/loss_vlb_step=0.000437, train/loss_step=0.103, global_step=413.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 415/20881 [37:48<31:04:46,  5.47s/it, loss=0.097, v_num=0, train/loss_simple_step=0.230, train/loss_vlb_step=0.051, train/loss_step=0.230, global_step=414.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 416/20881 [37:54<31:05:17,  5.47s/it, loss=0.0978, v_num=0, train/loss_simple_step=0.0758, train/loss_vlb_step=0.000268, train/loss_step=0.0758, global_step=415.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 417/20881 [38:00<31:05:22,  5.47s/it, loss=0.103, v_num=0, train/loss_simple_step=0.147, train/loss_vlb_step=0.00473, train/loss_step=0.147, global_step=416.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 418/20881 [38:05<31:04:55,  5.47s/it, loss=0.112, v_num=0, train/loss_simple_step=0.196, train/loss_vlb_step=0.000981, train/loss_step=0.196, global_step=417.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 419/20881 [38:10<31:04:38,  5.47s/it, loss=0.108, v_num=0, train/loss_simple_step=0.045, train/loss_vlb_step=0.000159, train/loss_step=0.045, global_step=418.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 420/20881 [38:16<31:04:18,  5.47s/it, loss=0.105, v_num=0, train/loss_simple_step=0.0824, train/loss_vlb_step=0.000344, train/loss_step=0.0824, global_step=419.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 421/20881 [38:21<31:03:58,  5.47s/it, loss=0.101, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.00058, train/loss_step=0.124, global_step=420.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 422/20881 [38:26<31:03:43,  5.47s/it, loss=0.105, v_num=0, train/loss_simple_step=0.143, train/loss_vlb_step=0.000872, train/loss_step=0.143, global_step=421.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 423/20881 [38:31<31:03:25,  5.47s/it, loss=0.107, v_num=0, train/loss_simple_step=0.149, train/loss_vlb_step=0.000884, train/loss_step=0.149, global_step=422.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 424/20881 [38:37<31:03:12,  5.46s/it, loss=0.105, v_num=0, train/loss_simple_step=0.0189, train/loss_vlb_step=7.2e-5, train/loss_step=0.0189, global_step=423.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 425/20881 [38:41<31:02:41,  5.46s/it, loss=0.105, v_num=0, train/loss_simple_step=0.110, train/loss_vlb_step=0.000647, train/loss_step=0.110, global_step=424.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 426/20881 [38:47<31:02:59,  5.46s/it, loss=0.111, v_num=0, train/loss_simple_step=0.161, train/loss_vlb_step=0.000861, train/loss_step=0.161, global_step=425.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 427/20881 [38:53<31:02:42,  5.46s/it, loss=0.114, v_num=0, train/loss_simple_step=0.152, train/loss_vlb_step=0.000738, train/loss_step=0.152, global_step=426.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 428/20881 [38:58<31:02:36,  5.46s/it, loss=0.105, v_num=0, train/loss_simple_step=0.0143, train/loss_vlb_step=5.51e-5, train/loss_step=0.0143, global_step=427.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 429/20881 [39:03<31:02:01,  5.46s/it, loss=0.108, v_num=0, train/loss_simple_step=0.119, train/loss_vlb_step=0.000452, train/loss_step=0.119, global_step=428.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 430/20881 [39:09<31:02:16,  5.46s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0173, train/loss_vlb_step=6.5e-5, train/loss_step=0.0173, global_step=429.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 431/20881 [39:14<31:01:51,  5.46s/it, loss=0.111, v_num=0, train/loss_simple_step=0.211, train/loss_vlb_step=0.00224, train/loss_step=0.211, global_step=430.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 432/20881 [39:19<31:01:38,  5.46s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0733, train/loss_vlb_step=0.000253, train/loss_step=0.0733, global_step=431.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 433/20881 [39:24<31:01:08,  5.46s/it, loss=0.116, v_num=0, train/loss_simple_step=0.143, train/loss_vlb_step=0.000804, train/loss_step=0.143, global_step=432.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 434/20881 [39:29<31:00:38,  5.46s/it, loss=0.121, v_num=0, train/loss_simple_step=0.204, train/loss_vlb_step=0.00476, train/loss_step=0.204, global_step=433.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 435/20881 [39:35<31:00:35,  5.46s/it, loss=0.114, v_num=0, train/loss_simple_step=0.094, train/loss_vlb_step=0.000387, train/loss_step=0.094, global_step=434.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 436/20881 [39:40<31:00:47,  5.46s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0853, train/loss_vlb_step=0.000424, train/loss_step=0.0853, global_step=435.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 437/20881 [39:47<31:01:35,  5.46s/it, loss=0.115, v_num=0, train/loss_simple_step=0.164, train/loss_vlb_step=0.00132, train/loss_step=0.164, global_step=436.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 438/20881 [39:52<31:00:59,  5.46s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0975, train/loss_vlb_step=0.000382, train/loss_step=0.0975, global_step=437.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 439/20881 [39:57<31:00:37,  5.46s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0531, train/loss_vlb_step=0.000179, train/loss_step=0.0531, global_step=438.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 440/20881 [40:03<31:01:01,  5.46s/it, loss=0.115, v_num=0, train/loss_simple_step=0.173, train/loss_vlb_step=0.000759, train/loss_step=0.173, global_step=439.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 441/20881 [40:09<31:00:56,  5.46s/it, loss=0.11, v_num=0, train/loss_simple_step=0.025, train/loss_vlb_step=8.99e-5, train/loss_step=0.025, global_step=440.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 442/20881 [40:14<31:00:48,  5.46s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0569, train/loss_vlb_step=0.000207, train/loss_step=0.0569, global_step=441.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 443/20881 [40:20<31:01:04,  5.46s/it, loss=0.101, v_num=0, train/loss_simple_step=0.0475, train/loss_vlb_step=0.000161, train/loss_step=0.0475, global_step=442.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 444/20881 [40:26<31:01:33,  5.47s/it, loss=0.103, v_num=0, train/loss_simple_step=0.0637, train/loss_vlb_step=0.000228, train/loss_step=0.0637, global_step=443.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 445/20881 [40:32<31:01:46,  5.47s/it, loss=0.106, v_num=0, train/loss_simple_step=0.166, train/loss_vlb_step=0.0157, train/loss_step=0.166, global_step=444.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 446/20881 [40:37<31:01:16,  5.46s/it, loss=0.102, v_num=0, train/loss_simple_step=0.074, train/loss_vlb_step=0.000269, train/loss_step=0.074, global_step=445.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 447/20881 [40:43<31:01:43,  5.47s/it, loss=0.0954, v_num=0, train/loss_simple_step=0.0251, train/loss_vlb_step=9.06e-5, train/loss_step=0.0251, global_step=446.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 448/20881 [40:49<31:01:46,  5.47s/it, loss=0.1, v_num=0, train/loss_simple_step=0.112, train/loss_vlb_step=0.000518, train/loss_step=0.112, global_step=447.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 449/20881 [40:55<31:02:07,  5.47s/it, loss=0.105, v_num=0, train/loss_simple_step=0.220, train/loss_vlb_step=0.00162, train/loss_step=0.220, global_step=448.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 450/20881 [41:00<31:01:43,  5.47s/it, loss=0.108, v_num=0, train/loss_simple_step=0.0613, train/loss_vlb_step=0.000211, train/loss_step=0.0613, global_step=449.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 451/20881 [41:06<31:01:54,  5.47s/it, loss=0.0977, v_num=0, train/loss_simple_step=0.0139, train/loss_vlb_step=5.37e-5, train/loss_step=0.0139, global_step=450.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 452/20881 [41:12<31:02:21,  5.47s/it, loss=0.1, v_num=0, train/loss_simple_step=0.129, train/loss_vlb_step=0.000987, train/loss_step=0.129, global_step=451.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 453/20881 [41:17<31:02:10,  5.47s/it, loss=0.0964, v_num=0, train/loss_simple_step=0.0621, train/loss_vlb_step=0.000272, train/loss_step=0.0621, global_step=452.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 454/20881 [41:22<31:01:57,  5.47s/it, loss=0.0916, v_num=0, train/loss_simple_step=0.107, train/loss_vlb_step=0.00109, train/loss_step=0.107, global_step=453.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 455/20881 [41:28<31:01:50,  5.47s/it, loss=0.0905, v_num=0, train/loss_simple_step=0.0732, train/loss_vlb_step=0.000335, train/loss_step=0.0732, global_step=454.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 456/20881 [41:34<31:02:11,  5.47s/it, loss=0.0924, v_num=0, train/loss_simple_step=0.123, train/loss_vlb_step=0.000553, train/loss_step=0.123, global_step=455.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 457/20881 [41:41<31:03:04,  5.47s/it, loss=0.0863, v_num=0, train/loss_simple_step=0.0425, train/loss_vlb_step=0.000158, train/loss_step=0.0425, global_step=456.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 458/20881 [41:47<31:03:21,  5.47s/it, loss=0.0865, v_num=0, train/loss_simple_step=0.101, train/loss_vlb_step=0.000436, train/loss_step=0.101, global_step=457.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 459/20881 [41:52<31:03:17,  5.47s/it, loss=0.0951, v_num=0, train/loss_simple_step=0.226, train/loss_vlb_step=0.00499, train/loss_step=0.226, global_step=458.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 460/20881 [41:58<31:03:26,  5.48s/it, loss=0.0892, v_num=0, train/loss_simple_step=0.0534, train/loss_vlb_step=0.000198, train/loss_step=0.0534, global_step=459.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 461/20881 [42:04<31:03:35,  5.48s/it, loss=0.0984, v_num=0, train/loss_simple_step=0.209, train/loss_vlb_step=0.00182, train/loss_step=0.209, global_step=460.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 462/20881 [42:09<31:03:17,  5.48s/it, loss=0.103, v_num=0, train/loss_simple_step=0.143, train/loss_vlb_step=0.000727, train/loss_step=0.143, global_step=461.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 463/20881 [42:14<31:02:41,  5.47s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0251, train/loss_vlb_step=9.06e-5, train/loss_step=0.0251, global_step=462.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 464/20881 [42:19<31:02:15,  5.47s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0803, train/loss_vlb_step=0.000293, train/loss_step=0.0803, global_step=463.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 465/20881 [42:23<31:01:33,  5.47s/it, loss=0.112, v_num=0, train/loss_simple_step=0.355, train/loss_vlb_step=0.0208, train/loss_step=0.355, global_step=464.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 466/20881 [42:28<31:00:55,  5.47s/it, loss=0.114, v_num=0, train/loss_simple_step=0.109, train/loss_vlb_step=0.00105, train/loss_step=0.109, global_step=465.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 467/20881 [42:34<31:01:01,  5.47s/it, loss=0.119, v_num=0, train/loss_simple_step=0.130, train/loss_vlb_step=0.00098, train/loss_step=0.130, global_step=466.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 468/20881 [42:39<31:00:38,  5.47s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0505, train/loss_vlb_step=0.000188, train/loss_step=0.0505, global_step=467.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 469/20881 [42:43<30:59:41,  5.47s/it, loss=0.111, v_num=0, train/loss_simple_step=0.123, train/loss_vlb_step=0.00168, train/loss_step=0.123, global_step=468.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 470/20881 [42:49<30:59:51,  5.47s/it, loss=0.119, v_num=0, train/loss_simple_step=0.216, train/loss_vlb_step=0.00197, train/loss_step=0.216, global_step=469.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 471/20881 [42:54<30:59:15,  5.47s/it, loss=0.123, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.000463, train/loss_step=0.105, global_step=470.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 472/20881 [43:00<30:59:19,  5.47s/it, loss=0.125, v_num=0, train/loss_simple_step=0.165, train/loss_vlb_step=0.00109, train/loss_step=0.165, global_step=471.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 473/20881 [43:04<30:58:50,  5.47s/it, loss=0.125, v_num=0, train/loss_simple_step=0.0649, train/loss_vlb_step=0.000293, train/loss_step=0.0649, global_step=472.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 474/20881 [43:10<30:58:41,  5.46s/it, loss=0.123, v_num=0, train/loss_simple_step=0.074, train/loss_vlb_step=0.000253, train/loss_step=0.074, global_step=473.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 475/20881 [43:14<30:57:46,  5.46s/it, loss=0.126, v_num=0, train/loss_simple_step=0.117, train/loss_vlb_step=0.000764, train/loss_step=0.117, global_step=474.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 476/20881 [43:20<30:57:43,  5.46s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0343, train/loss_vlb_step=0.000121, train/loss_step=0.0343, global_step=475.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 477/20881 [43:25<30:57:47,  5.46s/it, loss=0.12, v_num=0, train/loss_simple_step=0.012, train/loss_vlb_step=5.02e-5, train/loss_step=0.012, global_step=476.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 478/20881 [43:30<30:57:18,  5.46s/it, loss=0.118, v_num=0, train/loss_simple_step=0.0694, train/loss_vlb_step=0.000302, train/loss_step=0.0694, global_step=477.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 479/20881 [43:35<30:56:46,  5.46s/it, loss=0.121, v_num=0, train/loss_simple_step=0.285, train/loss_vlb_step=0.00388, train/loss_step=0.285, global_step=478.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 480/20881 [43:40<30:56:31,  5.46s/it, loss=0.12, v_num=0, train/loss_simple_step=0.0258, train/loss_vlb_step=9.2e-5, train/loss_step=0.0258, global_step=479.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 481/20881 [43:47<30:57:06,  5.46s/it, loss=0.116, v_num=0, train/loss_simple_step=0.129, train/loss_vlb_step=0.00117, train/loss_step=0.129, global_step=480.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 482/20881 [43:53<30:57:20,  5.46s/it, loss=0.114, v_num=0, train/loss_simple_step=0.117, train/loss_vlb_step=0.000477, train/loss_step=0.117, global_step=481.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 483/20881 [43:57<30:56:28,  5.46s/it, loss=0.118, v_num=0, train/loss_simple_step=0.097, train/loss_vlb_step=0.00037, train/loss_step=0.097, global_step=482.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 484/20881 [44:03<30:56:27,  5.46s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0357, train/loss_vlb_step=0.000124, train/loss_step=0.0357, global_step=483.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 485/20881 [44:07<30:55:49,  5.46s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0903, train/loss_vlb_step=0.000327, train/loss_step=0.0903, global_step=484.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 486/20881 [44:13<30:55:37,  5.46s/it, loss=0.105, v_num=0, train/loss_simple_step=0.164, train/loss_vlb_step=0.00122, train/loss_step=0.164, global_step=485.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 487/20881 [44:18<30:55:35,  5.46s/it, loss=0.104, v_num=0, train/loss_simple_step=0.106, train/loss_vlb_step=0.000404, train/loss_step=0.106, global_step=486.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 488/20881 [44:24<30:55:25,  5.46s/it, loss=0.12, v_num=0, train/loss_simple_step=0.361, train/loss_vlb_step=0.0335, train/loss_step=0.361, global_step=487.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 489/20881 [44:28<30:54:36,  5.46s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0597, train/loss_vlb_step=0.000244, train/loss_step=0.0597, global_step=488.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 490/20881 [44:34<30:54:38,  5.46s/it, loss=0.113, v_num=0, train/loss_simple_step=0.154, train/loss_vlb_step=0.0011, train/loss_step=0.154, global_step=489.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 491/20881 [44:39<30:54:18,  5.46s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0297, train/loss_vlb_step=0.000106, train/loss_step=0.0297, global_step=490.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 492/20881 [44:44<30:54:13,  5.46s/it, loss=0.116, v_num=0, train/loss_simple_step=0.294, train/loss_vlb_step=0.109, train/loss_step=0.294, global_step=491.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 493/20881 [44:49<30:53:32,  5.45s/it, loss=0.119, v_num=0, train/loss_simple_step=0.123, train/loss_vlb_step=0.000473, train/loss_step=0.123, global_step=492.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 494/20881 [44:54<30:53:17,  5.45s/it, loss=0.123, v_num=0, train/loss_simple_step=0.155, train/loss_vlb_step=0.00148, train/loss_step=0.155, global_step=493.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 495/20881 [44:59<30:52:46,  5.45s/it, loss=0.125, v_num=0, train/loss_simple_step=0.165, train/loss_vlb_step=0.00114, train/loss_step=0.165, global_step=494.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 496/20881 [45:04<30:52:23,  5.45s/it, loss=0.132, v_num=0, train/loss_simple_step=0.162, train/loss_vlb_step=0.000684, train/loss_step=0.162, global_step=495.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 497/20881 [45:10<30:52:50,  5.45s/it, loss=0.132, v_num=0, train/loss_simple_step=0.0213, train/loss_vlb_step=7.67e-5, train/loss_step=0.0213, global_step=496.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 498/20881 [45:15<30:52:44,  5.45s/it, loss=0.137, v_num=0, train/loss_simple_step=0.175, train/loss_vlb_step=0.00512, train/loss_step=0.175, global_step=497.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 499/20881 [45:22<30:53:02,  5.45s/it, loss=0.124, v_num=0, train/loss_simple_step=0.0124, train/loss_vlb_step=5.01e-5, train/loss_step=0.0124, global_step=498.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 500/20881 [45:27<30:53:04,  5.46s/it, loss=0.13, v_num=0, train/loss_simple_step=0.150, train/loss_vlb_step=0.00078, train/loss_step=0.150, global_step=499.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 501/20881 [45:33<30:53:13,  5.46s/it, loss=0.126, v_num=0, train/loss_simple_step=0.0572, train/loss_vlb_step=0.000201, train/loss_step=0.0572, global_step=500.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 502/20881 [45:38<30:52:56,  5.46s/it, loss=0.123, v_num=0, train/loss_simple_step=0.041, train/loss_vlb_step=0.00014, train/loss_step=0.041, global_step=501.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 503/20881 [45:43<30:52:37,  5.45s/it, loss=0.122, v_num=0, train/loss_simple_step=0.0904, train/loss_vlb_step=0.000356, train/loss_step=0.0904, global_step=502.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 504/20881 [45:48<30:52:05,  5.45s/it, loss=0.126, v_num=0, train/loss_simple_step=0.114, train/loss_vlb_step=0.000461, train/loss_step=0.114, global_step=503.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 505/20881 [45:53<30:51:40,  5.45s/it, loss=0.13, v_num=0, train/loss_simple_step=0.167, train/loss_vlb_step=0.00121, train/loss_step=0.167, global_step=504.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 506/20881 [45:58<30:51:26,  5.45s/it, loss=0.132, v_num=0, train/loss_simple_step=0.200, train/loss_vlb_step=0.00619, train/loss_step=0.200, global_step=505.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 507/20881 [46:04<30:51:14,  5.45s/it, loss=0.141, v_num=0, train/loss_simple_step=0.280, train/loss_vlb_step=0.00346, train/loss_step=0.280, global_step=506.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 508/20881 [46:08<30:50:42,  5.45s/it, loss=0.129, v_num=0, train/loss_simple_step=0.121, train/loss_vlb_step=0.000776, train/loss_step=0.121, global_step=507.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 509/20881 [46:13<30:50:17,  5.45s/it, loss=0.132, v_num=0, train/loss_simple_step=0.136, train/loss_vlb_step=0.000979, train/loss_step=0.136, global_step=508.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 510/20881 [46:19<30:50:28,  5.45s/it, loss=0.128, v_num=0, train/loss_simple_step=0.0595, train/loss_vlb_step=0.000279, train/loss_step=0.0595, global_step=509.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 511/20881 [46:24<30:49:54,  5.45s/it, loss=0.129, v_num=0, train/loss_simple_step=0.0524, train/loss_vlb_step=0.000201, train/loss_step=0.0524, global_step=510.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 512/20881 [46:28<30:49:07,  5.45s/it, loss=0.122, v_num=0, train/loss_simple_step=0.159, train/loss_vlb_step=0.0007, train/loss_step=0.159, global_step=511.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 513/20881 [46:34<30:49:02,  5.45s/it, loss=0.121, v_num=0, train/loss_simple_step=0.102, train/loss_vlb_step=0.000366, train/loss_step=0.102, global_step=512.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 514/20881 [46:39<30:48:51,  5.45s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0571, train/loss_vlb_step=0.000194, train/loss_step=0.0571, global_step=513.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 515/20881 [46:44<30:48:23,  5.45s/it, loss=0.115, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.00134, train/loss_step=0.144, global_step=514.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 516/20881 [46:49<30:48:01,  5.44s/it, loss=0.121, v_num=0, train/loss_simple_step=0.275, train/loss_vlb_step=0.0038, train/loss_step=0.275, global_step=515.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 517/20881 [46:54<30:47:55,  5.44s/it, loss=0.123, v_num=0, train/loss_simple_step=0.0738, train/loss_vlb_step=0.000263, train/loss_step=0.0738, global_step=516.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 518/20881 [47:00<30:47:52,  5.44s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0431, train/loss_vlb_step=0.00016, train/loss_step=0.0431, global_step=517.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 519/20881 [47:05<30:47:33,  5.44s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0472, train/loss_vlb_step=0.000171, train/loss_step=0.0472, global_step=518.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 520/20881 [47:10<30:46:59,  5.44s/it, loss=0.119, v_num=0, train/loss_simple_step=0.157, train/loss_vlb_step=0.00587, train/loss_step=0.157, global_step=519.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 521/20881 [47:17<30:47:46,  5.45s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0924, train/loss_vlb_step=0.000418, train/loss_step=0.0924, global_step=520.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   2%|▏         | 522/20881 [47:21<30:47:08,  5.44s/it, loss=0.122, v_num=0, train/loss_simple_step=0.071, train/loss_vlb_step=0.00024, train/loss_step=0.071, global_step=521.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 523/20881 [47:27<30:47:22,  5.44s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0601, train/loss_vlb_step=0.000207, train/loss_step=0.0601, global_step=522.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 524/20881 [47:33<30:47:21,  5.44s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0304, train/loss_vlb_step=0.000108, train/loss_step=0.0304, global_step=523.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 525/20881 [47:38<30:47:01,  5.44s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0291, train/loss_vlb_step=0.000103, train/loss_step=0.0291, global_step=524.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 526/20881 [47:44<30:47:35,  5.45s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0416, train/loss_vlb_step=0.000143, train/loss_step=0.0416, global_step=525.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 527/20881 [47:50<30:47:31,  5.45s/it, loss=0.0907, v_num=0, train/loss_simple_step=0.0624, train/loss_vlb_step=0.00026, train/loss_step=0.0624, global_step=526.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 528/20881 [47:57<30:48:24,  5.45s/it, loss=0.0854, v_num=0, train/loss_simple_step=0.0139, train/loss_vlb_step=5.76e-5, train/loss_step=0.0139, global_step=527.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 529/20881 [48:02<30:48:18,  5.45s/it, loss=0.0908, v_num=0, train/loss_simple_step=0.245, train/loss_vlb_step=0.114, train/loss_step=0.245, global_step=528.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 530/20881 [48:09<30:48:54,  5.45s/it, loss=0.095, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.00261, train/loss_step=0.144, global_step=529.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 531/20881 [48:14<30:48:51,  5.45s/it, loss=0.0942, v_num=0, train/loss_simple_step=0.0354, train/loss_vlb_step=0.000127, train/loss_step=0.0354, global_step=530.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 532/20881 [48:20<30:48:58,  5.45s/it, loss=0.0874, v_num=0, train/loss_simple_step=0.0245, train/loss_vlb_step=8.78e-5, train/loss_step=0.0245, global_step=531.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 533/20881 [48:26<30:49:28,  5.45s/it, loss=0.0858, v_num=0, train/loss_simple_step=0.0688, train/loss_vlb_step=0.000242, train/loss_step=0.0688, global_step=532.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 534/20881 [48:32<30:49:25,  5.45s/it, loss=0.0862, v_num=0, train/loss_simple_step=0.0641, train/loss_vlb_step=0.000304, train/loss_step=0.0641, global_step=533.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 535/20881 [48:37<30:49:08,  5.45s/it, loss=0.0804, v_num=0, train/loss_simple_step=0.0279, train/loss_vlb_step=0.0001, train/loss_step=0.0279, global_step=534.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 536/20881 [48:41<30:48:20,  5.45s/it, loss=0.0751, v_num=0, train/loss_simple_step=0.169, train/loss_vlb_step=0.000868, train/loss_step=0.169, global_step=535.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 537/20881 [48:48<30:48:58,  5.45s/it, loss=0.0805, v_num=0, train/loss_simple_step=0.182, train/loss_vlb_step=0.00278, train/loss_step=0.182, global_step=536.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 538/20881 [48:53<30:48:54,  5.45s/it, loss=0.0817, v_num=0, train/loss_simple_step=0.0683, train/loss_vlb_step=0.000251, train/loss_step=0.0683, global_step=537.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 539/20881 [48:58<30:48:23,  5.45s/it, loss=0.0817, v_num=0, train/loss_simple_step=0.0479, train/loss_vlb_step=0.000209, train/loss_step=0.0479, global_step=538.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 540/20881 [49:03<30:48:01,  5.45s/it, loss=0.0801, v_num=0, train/loss_simple_step=0.125, train/loss_vlb_step=0.000931, train/loss_step=0.125, global_step=539.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 541/20881 [49:08<30:47:22,  5.45s/it, loss=0.0797, v_num=0, train/loss_simple_step=0.0848, train/loss_vlb_step=0.000329, train/loss_step=0.0848, global_step=540.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 542/20881 [49:13<30:47:10,  5.45s/it, loss=0.0892, v_num=0, train/loss_simple_step=0.261, train/loss_vlb_step=0.104, train/loss_step=0.261, global_step=541.0]     \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 543/20881 [49:18<30:47:05,  5.45s/it, loss=0.0993, v_num=0, train/loss_simple_step=0.261, train/loss_vlb_step=0.00532, train/loss_step=0.261, global_step=542.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 544/20881 [49:23<30:46:35,  5.45s/it, loss=0.109, v_num=0, train/loss_simple_step=0.218, train/loss_vlb_step=0.0017, train/loss_step=0.218, global_step=543.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 545/20881 [49:28<30:46:12,  5.45s/it, loss=0.113, v_num=0, train/loss_simple_step=0.112, train/loss_vlb_step=0.000448, train/loss_step=0.112, global_step=544.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 546/20881 [49:33<30:45:36,  5.45s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0659, train/loss_vlb_step=0.000463, train/loss_step=0.0659, global_step=545.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 547/20881 [49:38<30:45:07,  5.44s/it, loss=0.122, v_num=0, train/loss_simple_step=0.216, train/loss_vlb_step=0.00529, train/loss_step=0.216, global_step=546.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 548/20881 [49:42<30:44:20,  5.44s/it, loss=0.122, v_num=0, train/loss_simple_step=0.0224, train/loss_vlb_step=7.89e-5, train/loss_step=0.0224, global_step=547.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 549/20881 [49:47<30:44:10,  5.44s/it, loss=0.115, v_num=0, train/loss_simple_step=0.100, train/loss_vlb_step=0.000637, train/loss_step=0.100, global_step=548.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 550/20881 [49:53<30:44:05,  5.44s/it, loss=0.108, v_num=0, train/loss_simple_step=0.00936, train/loss_vlb_step=3.9e-5, train/loss_step=0.00936, global_step=549.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 551/20881 [49:59<30:44:24,  5.44s/it, loss=0.114, v_num=0, train/loss_simple_step=0.149, train/loss_vlb_step=0.00136, train/loss_step=0.149, global_step=550.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 552/20881 [50:04<30:44:15,  5.44s/it, loss=0.118, v_num=0, train/loss_simple_step=0.0997, train/loss_vlb_step=0.000417, train/loss_step=0.0997, global_step=551.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 553/20881 [50:09<30:43:34,  5.44s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0506, train/loss_vlb_step=0.000197, train/loss_step=0.0506, global_step=552.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 554/20881 [50:14<30:43:20,  5.44s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0741, train/loss_vlb_step=0.000362, train/loss_step=0.0741, global_step=553.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 555/20881 [50:20<30:43:23,  5.44s/it, loss=0.123, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.00323, train/loss_step=0.144, global_step=554.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 556/20881 [50:26<30:43:38,  5.44s/it, loss=0.121, v_num=0, train/loss_simple_step=0.130, train/loss_vlb_step=0.00101, train/loss_step=0.130, global_step=555.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 557/20881 [50:30<30:43:10,  5.44s/it, loss=0.118, v_num=0, train/loss_simple_step=0.114, train/loss_vlb_step=0.00099, train/loss_step=0.114, global_step=556.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 558/20881 [50:35<30:42:43,  5.44s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0843, train/loss_vlb_step=0.0003, train/loss_step=0.0843, global_step=557.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 559/20881 [50:40<30:42:25,  5.44s/it, loss=0.129, v_num=0, train/loss_simple_step=0.266, train/loss_vlb_step=0.00169, train/loss_step=0.266, global_step=558.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 560/20881 [50:46<30:42:23,  5.44s/it, loss=0.133, v_num=0, train/loss_simple_step=0.195, train/loss_vlb_step=0.000922, train/loss_step=0.195, global_step=559.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 561/20881 [50:51<30:42:11,  5.44s/it, loss=0.133, v_num=0, train/loss_simple_step=0.0951, train/loss_vlb_step=0.00043, train/loss_step=0.0951, global_step=560.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 562/20881 [50:57<30:42:39,  5.44s/it, loss=0.128, v_num=0, train/loss_simple_step=0.157, train/loss_vlb_step=0.00115, train/loss_step=0.157, global_step=561.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 563/20881 [51:02<30:42:14,  5.44s/it, loss=0.125, v_num=0, train/loss_simple_step=0.189, train/loss_vlb_step=0.00267, train/loss_step=0.189, global_step=562.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 564/20881 [51:08<30:42:30,  5.44s/it, loss=0.115, v_num=0, train/loss_simple_step=0.0248, train/loss_vlb_step=8.98e-5, train/loss_step=0.0248, global_step=563.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 565/20881 [51:14<30:42:36,  5.44s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0478, train/loss_vlb_step=0.000164, train/loss_step=0.0478, global_step=564.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 566/20881 [51:20<30:43:01,  5.44s/it, loss=0.118, v_num=0, train/loss_simple_step=0.183, train/loss_vlb_step=0.000852, train/loss_step=0.183, global_step=565.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 567/20881 [51:25<30:42:36,  5.44s/it, loss=0.11, v_num=0, train/loss_simple_step=0.065, train/loss_vlb_step=0.000236, train/loss_step=0.065, global_step=566.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 568/20881 [51:31<30:42:44,  5.44s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0829, train/loss_vlb_step=0.000307, train/loss_step=0.0829, global_step=567.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 569/20881 [51:37<30:42:36,  5.44s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0408, train/loss_vlb_step=0.000139, train/loss_step=0.0408, global_step=568.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 570/20881 [51:42<30:42:44,  5.44s/it, loss=0.115, v_num=0, train/loss_simple_step=0.118, train/loss_vlb_step=0.00085, train/loss_step=0.118, global_step=569.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 571/20881 [51:47<30:42:26,  5.44s/it, loss=0.118, v_num=0, train/loss_simple_step=0.200, train/loss_vlb_step=0.00155, train/loss_step=0.200, global_step=570.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 572/20881 [51:53<30:42:12,  5.44s/it, loss=0.117, v_num=0, train/loss_simple_step=0.082, train/loss_vlb_step=0.000297, train/loss_step=0.082, global_step=571.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 573/20881 [51:58<30:42:17,  5.44s/it, loss=0.12, v_num=0, train/loss_simple_step=0.100, train/loss_vlb_step=0.000566, train/loss_step=0.100, global_step=572.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 574/20881 [52:04<30:42:11,  5.44s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0684, train/loss_vlb_step=0.000246, train/loss_step=0.0684, global_step=573.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 575/20881 [52:09<30:42:00,  5.44s/it, loss=0.127, v_num=0, train/loss_simple_step=0.291, train/loss_vlb_step=0.00236, train/loss_step=0.291, global_step=574.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 576/20881 [52:14<30:41:39,  5.44s/it, loss=0.129, v_num=0, train/loss_simple_step=0.187, train/loss_vlb_step=0.00123, train/loss_step=0.187, global_step=575.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 577/20881 [52:19<30:41:14,  5.44s/it, loss=0.128, v_num=0, train/loss_simple_step=0.0755, train/loss_vlb_step=0.000306, train/loss_step=0.0755, global_step=576.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 578/20881 [52:24<30:40:51,  5.44s/it, loss=0.126, v_num=0, train/loss_simple_step=0.049, train/loss_vlb_step=0.00017, train/loss_step=0.049, global_step=577.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 579/20881 [52:30<30:41:01,  5.44s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0668, train/loss_vlb_step=0.000242, train/loss_step=0.0668, global_step=578.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 580/20881 [52:35<30:41:02,  5.44s/it, loss=0.109, v_num=0, train/loss_simple_step=0.0685, train/loss_vlb_step=0.000262, train/loss_step=0.0685, global_step=579.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 581/20881 [52:40<30:40:44,  5.44s/it, loss=0.108, v_num=0, train/loss_simple_step=0.0737, train/loss_vlb_step=0.000255, train/loss_step=0.0737, global_step=580.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 582/20881 [52:46<30:40:52,  5.44s/it, loss=0.108, v_num=0, train/loss_simple_step=0.140, train/loss_vlb_step=0.00117, train/loss_step=0.140, global_step=581.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 583/20881 [52:51<30:40:34,  5.44s/it, loss=0.104, v_num=0, train/loss_simple_step=0.119, train/loss_vlb_step=0.000731, train/loss_step=0.119, global_step=582.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 584/20881 [52:56<30:40:15,  5.44s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0632, train/loss_vlb_step=0.000228, train/loss_step=0.0632, global_step=583.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 585/20881 [53:01<30:39:53,  5.44s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0619, train/loss_vlb_step=0.000214, train/loss_step=0.0619, global_step=584.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 586/20881 [53:07<30:39:47,  5.44s/it, loss=0.113, v_num=0, train/loss_simple_step=0.302, train/loss_vlb_step=0.0055, train/loss_step=0.302, global_step=585.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 587/20881 [53:12<30:39:40,  5.44s/it, loss=0.115, v_num=0, train/loss_simple_step=0.119, train/loss_vlb_step=0.000539, train/loss_step=0.119, global_step=586.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 588/20881 [53:18<30:39:47,  5.44s/it, loss=0.117, v_num=0, train/loss_simple_step=0.119, train/loss_vlb_step=0.000456, train/loss_step=0.119, global_step=587.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 589/20881 [53:23<30:39:21,  5.44s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0312, train/loss_vlb_step=0.000111, train/loss_step=0.0312, global_step=588.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 590/20881 [53:28<30:38:59,  5.44s/it, loss=0.122, v_num=0, train/loss_simple_step=0.222, train/loss_vlb_step=0.00219, train/loss_step=0.222, global_step=589.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 591/20881 [53:33<30:38:37,  5.44s/it, loss=0.114, v_num=0, train/loss_simple_step=0.035, train/loss_vlb_step=0.000126, train/loss_step=0.035, global_step=590.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 592/20881 [53:38<30:38:10,  5.44s/it, loss=0.116, v_num=0, train/loss_simple_step=0.129, train/loss_vlb_step=0.000602, train/loss_step=0.129, global_step=591.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 593/20881 [53:42<30:37:44,  5.43s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0654, train/loss_vlb_step=0.00024, train/loss_step=0.0654, global_step=592.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 594/20881 [53:48<30:37:34,  5.43s/it, loss=0.116, v_num=0, train/loss_simple_step=0.0947, train/loss_vlb_step=0.000396, train/loss_step=0.0947, global_step=593.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 595/20881 [53:53<30:37:16,  5.43s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0984, train/loss_vlb_step=0.00036, train/loss_step=0.0984, global_step=594.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 596/20881 [53:58<30:37:15,  5.43s/it, loss=0.101, v_num=0, train/loss_simple_step=0.092, train/loss_vlb_step=0.000367, train/loss_step=0.092, global_step=595.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 597/20881 [54:03<30:36:50,  5.43s/it, loss=0.108, v_num=0, train/loss_simple_step=0.203, train/loss_vlb_step=0.00442, train/loss_step=0.203, global_step=596.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 598/20881 [54:09<30:36:40,  5.43s/it, loss=0.114, v_num=0, train/loss_simple_step=0.168, train/loss_vlb_step=0.0011, train/loss_step=0.168, global_step=597.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 599/20881 [54:13<30:36:05,  5.43s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0612, train/loss_vlb_step=0.000215, train/loss_step=0.0612, global_step=598.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 600/20881 [54:18<30:35:54,  5.43s/it, loss=0.115, v_num=0, train/loss_simple_step=0.0942, train/loss_vlb_step=0.000322, train/loss_step=0.0942, global_step=599.0]\n",
      "\n",
      "\n",
      "\n",
      "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▏         | 1/50 [00:00<00:22,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:   4%|▍         | 2/50 [00:00<00:21,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:   6%|▌         | 3/50 [00:01<00:21,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:   8%|▊         | 4/50 [00:01<00:20,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  10%|█         | 5/50 [00:02<00:20,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  12%|█▏        | 6/50 [00:02<00:19,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  14%|█▍        | 7/50 [00:03<00:19,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  16%|█▌        | 8/50 [00:03<00:19,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█▊        | 9/50 [00:04<00:18,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  20%|██        | 10/50 [00:04<00:18,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██▏       | 11/50 [00:04<00:17,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██▍       | 12/50 [00:05<00:17,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  26%|██▌       | 13/50 [00:05<00:16,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  28%|██▊       | 14/50 [00:06<00:16,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  30%|███       | 15/50 [00:06<00:15,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  32%|███▏      | 16/50 [00:07<00:15,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  34%|███▍      | 17/50 [00:07<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  36%|███▌      | 18/50 [00:08<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███▊      | 19/50 [00:08<00:14,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  40%|████      | 20/50 [00:09<00:13,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████▏     | 21/50 [00:09<00:13,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████▍     | 22/50 [00:09<00:12,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  46%|████▌     | 23/50 [00:10<00:12,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  48%|████▊     | 24/50 [00:10<00:11,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  50%|█████     | 25/50 [00:11<00:11,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  52%|█████▏    | 26/50 [00:11<00:10,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  54%|█████▍    | 27/50 [00:12<00:10,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  56%|█████▌    | 28/50 [00:12<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  58%|█████▊    | 29/50 [00:13<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  60%|██████    | 30/50 [00:13<00:09,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  62%|██████▏   | 31/50 [00:14<00:08,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████▍   | 32/50 [00:14<00:08,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  66%|██████▌   | 33/50 [00:14<00:07,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  68%|██████▊   | 34/50 [00:15<00:07,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  70%|███████   | 35/50 [00:15<00:06,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  72%|███████▏  | 36/50 [00:16<00:06,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  74%|███████▍  | 37/50 [00:16<00:05,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  76%|███████▌  | 38/50 [00:17<00:05,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  78%|███████▊  | 39/50 [00:17<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  80%|████████  | 40/50 [00:18<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  82%|████████▏ | 41/50 [00:18<00:04,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████▍ | 42/50 [00:19<00:03,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████▌ | 43/50 [00:19<00:03,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  88%|████████▊ | 44/50 [00:19<00:02,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  90%|█████████ | 45/50 [00:20<00:02,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  92%|█████████▏| 46/50 [00:20<00:01,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  94%|█████████▍| 47/50 [00:21<00:01,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  96%|█████████▌| 48/50 [00:21<00:00,  2.21it/s]\u001b[A\n",
      "DDIM Sampler:  98%|█████████▊| 49/50 [00:22<00:00,  2.21it/s]\u001b[A\n",
      "DDIM Sampler: 100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 601/20881 [54:52<30:51:25,  5.48s/it, loss=0.125, v_num=0, train/loss_simple_step=0.283, train/loss_vlb_step=0.010, train/loss_step=0.283, global_step=600.0]     \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 602/20881 [54:55<30:50:23,  5.47s/it, loss=0.129, v_num=0, train/loss_simple_step=0.220, train/loss_vlb_step=0.00146, train/loss_step=0.220, global_step=601.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 603/20881 [55:01<30:50:09,  5.47s/it, loss=0.133, v_num=0, train/loss_simple_step=0.189, train/loss_vlb_step=0.00216, train/loss_step=0.189, global_step=602.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 604/20881 [55:06<30:49:54,  5.47s/it, loss=0.135, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.000408, train/loss_step=0.105, global_step=603.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 605/20881 [55:11<30:49:42,  5.47s/it, loss=0.136, v_num=0, train/loss_simple_step=0.0873, train/loss_vlb_step=0.000426, train/loss_step=0.0873, global_step=604.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 606/20881 [55:16<30:49:19,  5.47s/it, loss=0.13, v_num=0, train/loss_simple_step=0.174, train/loss_vlb_step=0.00178, train/loss_step=0.174, global_step=605.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 607/20881 [55:21<30:48:55,  5.47s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0738, train/loss_vlb_step=0.000308, train/loss_step=0.0738, global_step=606.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 608/20881 [55:26<30:48:32,  5.47s/it, loss=0.127, v_num=0, train/loss_simple_step=0.116, train/loss_vlb_step=0.000833, train/loss_step=0.116, global_step=607.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 609/20881 [55:31<30:48:29,  5.47s/it, loss=0.132, v_num=0, train/loss_simple_step=0.120, train/loss_vlb_step=0.000447, train/loss_step=0.120, global_step=608.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 610/20881 [55:37<30:48:23,  5.47s/it, loss=0.123, v_num=0, train/loss_simple_step=0.0421, train/loss_vlb_step=0.000144, train/loss_step=0.0421, global_step=609.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 611/20881 [55:43<30:48:30,  5.47s/it, loss=0.123, v_num=0, train/loss_simple_step=0.0435, train/loss_vlb_step=0.000154, train/loss_step=0.0435, global_step=610.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 612/20881 [55:48<30:48:26,  5.47s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0927, train/loss_vlb_step=0.000325, train/loss_step=0.0927, global_step=611.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 613/20881 [55:54<30:48:18,  5.47s/it, loss=0.12, v_num=0, train/loss_simple_step=0.034, train/loss_vlb_step=0.000123, train/loss_step=0.034, global_step=612.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 614/20881 [55:59<30:48:18,  5.47s/it, loss=0.122, v_num=0, train/loss_simple_step=0.138, train/loss_vlb_step=0.00115, train/loss_step=0.138, global_step=613.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 615/20881 [56:05<30:48:11,  5.47s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0909, train/loss_vlb_step=0.000507, train/loss_step=0.0909, global_step=614.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 616/20881 [56:11<30:48:33,  5.47s/it, loss=0.128, v_num=0, train/loss_simple_step=0.226, train/loss_vlb_step=0.00593, train/loss_step=0.226, global_step=615.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 617/20881 [56:16<30:48:24,  5.47s/it, loss=0.127, v_num=0, train/loss_simple_step=0.183, train/loss_vlb_step=0.00203, train/loss_step=0.183, global_step=616.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 618/20881 [56:23<30:48:42,  5.47s/it, loss=0.129, v_num=0, train/loss_simple_step=0.209, train/loss_vlb_step=0.00109, train/loss_step=0.209, global_step=617.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 619/20881 [56:28<30:48:44,  5.47s/it, loss=0.138, v_num=0, train/loss_simple_step=0.240, train/loss_vlb_step=0.00489, train/loss_step=0.240, global_step=618.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 620/20881 [56:34<30:48:41,  5.47s/it, loss=0.136, v_num=0, train/loss_simple_step=0.0538, train/loss_vlb_step=0.000207, train/loss_step=0.0538, global_step=619.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 621/20881 [56:39<30:48:24,  5.47s/it, loss=0.131, v_num=0, train/loss_simple_step=0.191, train/loss_vlb_step=0.00185, train/loss_step=0.191, global_step=620.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 622/20881 [56:44<30:48:16,  5.47s/it, loss=0.124, v_num=0, train/loss_simple_step=0.0674, train/loss_vlb_step=0.000277, train/loss_step=0.0674, global_step=621.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 623/20881 [56:50<30:48:14,  5.47s/it, loss=0.127, v_num=0, train/loss_simple_step=0.243, train/loss_vlb_step=0.00916, train/loss_step=0.243, global_step=622.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 624/20881 [56:55<30:47:54,  5.47s/it, loss=0.124, v_num=0, train/loss_simple_step=0.0572, train/loss_vlb_step=0.00019, train/loss_step=0.0572, global_step=623.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 625/20881 [57:00<30:47:48,  5.47s/it, loss=0.122, v_num=0, train/loss_simple_step=0.0519, train/loss_vlb_step=0.000192, train/loss_step=0.0519, global_step=624.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 626/20881 [57:05<30:47:22,  5.47s/it, loss=0.121, v_num=0, train/loss_simple_step=0.143, train/loss_vlb_step=0.000805, train/loss_step=0.143, global_step=625.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 627/20881 [57:10<30:47:07,  5.47s/it, loss=0.122, v_num=0, train/loss_simple_step=0.0949, train/loss_vlb_step=0.000691, train/loss_step=0.0949, global_step=626.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 628/20881 [57:15<30:46:43,  5.47s/it, loss=0.123, v_num=0, train/loss_simple_step=0.134, train/loss_vlb_step=0.00082, train/loss_step=0.134, global_step=627.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 629/20881 [57:20<30:45:58,  5.47s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0863, train/loss_vlb_step=0.000355, train/loss_step=0.0863, global_step=628.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 630/20881 [57:24<30:45:25,  5.47s/it, loss=0.121, v_num=0, train/loss_simple_step=0.048, train/loss_vlb_step=0.00019, train/loss_step=0.048, global_step=629.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 631/20881 [57:30<30:45:25,  5.47s/it, loss=0.126, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.000751, train/loss_step=0.144, global_step=630.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 632/20881 [57:35<30:45:15,  5.47s/it, loss=0.128, v_num=0, train/loss_simple_step=0.126, train/loss_vlb_step=0.0019, train/loss_step=0.126, global_step=631.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 633/20881 [57:40<30:44:54,  5.47s/it, loss=0.13, v_num=0, train/loss_simple_step=0.0764, train/loss_vlb_step=0.000281, train/loss_step=0.0764, global_step=632.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 634/20881 [57:45<30:44:37,  5.47s/it, loss=0.132, v_num=0, train/loss_simple_step=0.179, train/loss_vlb_step=0.000805, train/loss_step=0.179, global_step=633.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 635/20881 [57:50<30:44:09,  5.47s/it, loss=0.13, v_num=0, train/loss_simple_step=0.0397, train/loss_vlb_step=0.000137, train/loss_step=0.0397, global_step=634.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 636/20881 [57:54<30:43:28,  5.46s/it, loss=0.119, v_num=0, train/loss_simple_step=0.0187, train/loss_vlb_step=7.24e-5, train/loss_step=0.0187, global_step=635.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 637/20881 [57:59<30:43:02,  5.46s/it, loss=0.122, v_num=0, train/loss_simple_step=0.246, train/loss_vlb_step=0.00949, train/loss_step=0.246, global_step=636.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 638/20881 [58:04<30:42:41,  5.46s/it, loss=0.118, v_num=0, train/loss_simple_step=0.120, train/loss_vlb_step=0.000676, train/loss_step=0.120, global_step=637.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 639/20881 [58:11<30:43:19,  5.46s/it, loss=0.111, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.000535, train/loss_step=0.105, global_step=638.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 640/20881 [58:17<30:43:18,  5.46s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0333, train/loss_vlb_step=0.000118, train/loss_step=0.0333, global_step=639.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 641/20881 [58:23<30:43:32,  5.47s/it, loss=0.105, v_num=0, train/loss_simple_step=0.0888, train/loss_vlb_step=0.000358, train/loss_step=0.0888, global_step=640.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 642/20881 [58:28<30:43:16,  5.46s/it, loss=0.112, v_num=0, train/loss_simple_step=0.199, train/loss_vlb_step=0.00138, train/loss_step=0.199, global_step=641.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 643/20881 [58:34<30:43:31,  5.47s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0152, train/loss_vlb_step=6.04e-5, train/loss_step=0.0152, global_step=642.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 644/20881 [58:39<30:43:21,  5.47s/it, loss=0.099, v_num=0, train/loss_simple_step=0.0309, train/loss_vlb_step=0.000107, train/loss_step=0.0309, global_step=643.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 645/20881 [58:45<30:43:16,  5.47s/it, loss=0.105, v_num=0, train/loss_simple_step=0.167, train/loss_vlb_step=0.00232, train/loss_step=0.167, global_step=644.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 646/20881 [58:50<30:43:01,  5.46s/it, loss=0.1, v_num=0, train/loss_simple_step=0.0522, train/loss_vlb_step=0.000183, train/loss_step=0.0522, global_step=645.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 647/20881 [58:54<30:42:16,  5.46s/it, loss=0.0976, v_num=0, train/loss_simple_step=0.0415, train/loss_vlb_step=0.000142, train/loss_step=0.0415, global_step=646.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 648/20881 [58:59<30:41:42,  5.46s/it, loss=0.0975, v_num=0, train/loss_simple_step=0.132, train/loss_vlb_step=0.000748, train/loss_step=0.132, global_step=647.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 649/20881 [59:04<30:41:39,  5.46s/it, loss=0.0992, v_num=0, train/loss_simple_step=0.120, train/loss_vlb_step=0.00076, train/loss_step=0.120, global_step=648.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 650/20881 [59:09<30:41:20,  5.46s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0968, train/loss_vlb_step=0.000405, train/loss_step=0.0968, global_step=649.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 651/20881 [59:15<30:41:32,  5.46s/it, loss=0.0972, v_num=0, train/loss_simple_step=0.0557, train/loss_vlb_step=0.000196, train/loss_step=0.0557, global_step=650.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 652/20881 [59:20<30:40:57,  5.46s/it, loss=0.0941, v_num=0, train/loss_simple_step=0.0634, train/loss_vlb_step=0.000362, train/loss_step=0.0634, global_step=651.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 653/20881 [59:24<30:40:26,  5.46s/it, loss=0.105, v_num=0, train/loss_simple_step=0.291, train/loss_vlb_step=0.00778, train/loss_step=0.291, global_step=652.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 654/20881 [59:30<30:40:23,  5.46s/it, loss=0.0995, v_num=0, train/loss_simple_step=0.074, train/loss_vlb_step=0.000279, train/loss_step=0.074, global_step=653.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 655/20881 [59:35<30:40:24,  5.46s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0846, train/loss_vlb_step=0.000303, train/loss_step=0.0846, global_step=654.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 656/20881 [59:40<30:39:52,  5.46s/it, loss=0.105, v_num=0, train/loss_simple_step=0.076, train/loss_vlb_step=0.000458, train/loss_step=0.076, global_step=655.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 657/20881 [59:46<30:40:13,  5.46s/it, loss=0.0926, v_num=0, train/loss_simple_step=0.0043, train/loss_vlb_step=2.19e-5, train/loss_step=0.0043, global_step=656.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 658/20881 [59:52<30:40:02,  5.46s/it, loss=0.097, v_num=0, train/loss_simple_step=0.208, train/loss_vlb_step=0.0022, train/loss_step=0.208, global_step=657.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 659/20881 [59:57<30:39:52,  5.46s/it, loss=0.0999, v_num=0, train/loss_simple_step=0.164, train/loss_vlb_step=0.00693, train/loss_step=0.164, global_step=658.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 660/20881 [1:00:02<30:39:35,  5.46s/it, loss=0.0994, v_num=0, train/loss_simple_step=0.0233, train/loss_vlb_step=8.73e-5, train/loss_step=0.0233, global_step=659.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 661/20881 [1:00:08<30:39:44,  5.46s/it, loss=0.103, v_num=0, train/loss_simple_step=0.167, train/loss_vlb_step=0.00192, train/loss_step=0.167, global_step=660.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 662/20881 [1:00:13<30:39:31,  5.46s/it, loss=0.0968, v_num=0, train/loss_simple_step=0.0686, train/loss_vlb_step=0.000245, train/loss_step=0.0686, global_step=661.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 663/20881 [1:00:19<30:39:20,  5.46s/it, loss=0.0965, v_num=0, train/loss_simple_step=0.0086, train/loss_vlb_step=3.84e-5, train/loss_step=0.0086, global_step=662.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 664/20881 [1:00:25<30:39:48,  5.46s/it, loss=0.103, v_num=0, train/loss_simple_step=0.161, train/loss_vlb_step=0.000791, train/loss_step=0.161, global_step=663.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 665/20881 [1:00:30<30:39:26,  5.46s/it, loss=0.108, v_num=0, train/loss_simple_step=0.271, train/loss_vlb_step=0.00528, train/loss_step=0.271, global_step=664.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 666/20881 [1:00:35<30:39:14,  5.46s/it, loss=0.113, v_num=0, train/loss_simple_step=0.157, train/loss_vlb_step=0.00136, train/loss_step=0.157, global_step=665.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 667/20881 [1:00:40<30:38:58,  5.46s/it, loss=0.117, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000385, train/loss_step=0.104, global_step=666.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 668/20881 [1:00:45<30:38:24,  5.46s/it, loss=0.122, v_num=0, train/loss_simple_step=0.233, train/loss_vlb_step=0.0021, train/loss_step=0.233, global_step=667.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 669/20881 [1:00:49<30:37:46,  5.46s/it, loss=0.12, v_num=0, train/loss_simple_step=0.0869, train/loss_vlb_step=0.00029, train/loss_step=0.0869, global_step=668.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 670/20881 [1:00:54<30:37:31,  5.46s/it, loss=0.122, v_num=0, train/loss_simple_step=0.146, train/loss_vlb_step=0.000828, train/loss_step=0.146, global_step=669.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 671/20881 [1:00:59<30:36:59,  5.45s/it, loss=0.126, v_num=0, train/loss_simple_step=0.133, train/loss_vlb_step=0.00223, train/loss_step=0.133, global_step=670.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 672/20881 [1:01:03<30:36:24,  5.45s/it, loss=0.135, v_num=0, train/loss_simple_step=0.248, train/loss_vlb_step=0.00285, train/loss_step=0.248, global_step=671.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 673/20881 [1:01:08<30:35:55,  5.45s/it, loss=0.127, v_num=0, train/loss_simple_step=0.130, train/loss_vlb_step=0.00178, train/loss_step=0.130, global_step=672.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 674/20881 [1:01:13<30:35:41,  5.45s/it, loss=0.126, v_num=0, train/loss_simple_step=0.0435, train/loss_vlb_step=0.000149, train/loss_step=0.0435, global_step=673.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 675/20881 [1:01:19<30:35:47,  5.45s/it, loss=0.124, v_num=0, train/loss_simple_step=0.0397, train/loss_vlb_step=0.00014, train/loss_step=0.0397, global_step=674.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 676/20881 [1:01:23<30:34:57,  5.45s/it, loss=0.127, v_num=0, train/loss_simple_step=0.137, train/loss_vlb_step=0.000914, train/loss_step=0.137, global_step=675.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 677/20881 [1:01:28<30:34:23,  5.45s/it, loss=0.136, v_num=0, train/loss_simple_step=0.196, train/loss_vlb_step=0.000929, train/loss_step=0.196, global_step=676.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 678/20881 [1:01:33<30:34:14,  5.45s/it, loss=0.133, v_num=0, train/loss_simple_step=0.140, train/loss_vlb_step=0.000949, train/loss_step=0.140, global_step=677.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 679/20881 [1:01:39<30:34:24,  5.45s/it, loss=0.133, v_num=0, train/loss_simple_step=0.176, train/loss_vlb_step=0.00238, train/loss_step=0.176, global_step=678.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 680/20881 [1:01:44<30:34:23,  5.45s/it, loss=0.134, v_num=0, train/loss_simple_step=0.0251, train/loss_vlb_step=9.25e-5, train/loss_step=0.0251, global_step=679.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 681/20881 [1:01:49<30:34:03,  5.45s/it, loss=0.132, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.00057, train/loss_step=0.144, global_step=680.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 682/20881 [1:01:54<30:33:32,  5.45s/it, loss=0.132, v_num=0, train/loss_simple_step=0.0544, train/loss_vlb_step=0.000208, train/loss_step=0.0544, global_step=681.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 683/20881 [1:01:59<30:33:18,  5.45s/it, loss=0.135, v_num=0, train/loss_simple_step=0.0646, train/loss_vlb_step=0.000226, train/loss_step=0.0646, global_step=682.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 684/20881 [1:02:04<30:32:59,  5.45s/it, loss=0.128, v_num=0, train/loss_simple_step=0.0214, train/loss_vlb_step=7.58e-5, train/loss_step=0.0214, global_step=683.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 685/20881 [1:02:10<30:33:00,  5.45s/it, loss=0.119, v_num=0, train/loss_simple_step=0.103, train/loss_vlb_step=0.000506, train/loss_step=0.103, global_step=684.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 686/20881 [1:02:15<30:32:42,  5.45s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0267, train/loss_vlb_step=9.64e-5, train/loss_step=0.0267, global_step=685.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 687/20881 [1:02:21<30:33:04,  5.45s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0602, train/loss_vlb_step=0.000203, train/loss_step=0.0602, global_step=686.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 688/20881 [1:02:27<30:33:08,  5.45s/it, loss=0.0992, v_num=0, train/loss_simple_step=0.00907, train/loss_vlb_step=4.02e-5, train/loss_step=0.00907, global_step=687.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 689/20881 [1:02:33<30:33:06,  5.45s/it, loss=0.0971, v_num=0, train/loss_simple_step=0.0438, train/loss_vlb_step=0.000176, train/loss_step=0.0438, global_step=688.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 690/20881 [1:02:39<30:33:20,  5.45s/it, loss=0.0987, v_num=0, train/loss_simple_step=0.179, train/loss_vlb_step=0.00272, train/loss_step=0.179, global_step=689.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 691/20881 [1:02:44<30:33:10,  5.45s/it, loss=0.0975, v_num=0, train/loss_simple_step=0.108, train/loss_vlb_step=0.000594, train/loss_step=0.108, global_step=690.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 692/20881 [1:02:50<30:33:21,  5.45s/it, loss=0.0936, v_num=0, train/loss_simple_step=0.170, train/loss_vlb_step=0.000853, train/loss_step=0.170, global_step=691.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 693/20881 [1:02:56<30:33:47,  5.45s/it, loss=0.088, v_num=0, train/loss_simple_step=0.0182, train/loss_vlb_step=6.75e-5, train/loss_step=0.0182, global_step=692.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 694/20881 [1:03:01<30:33:27,  5.45s/it, loss=0.0976, v_num=0, train/loss_simple_step=0.235, train/loss_vlb_step=0.00297, train/loss_step=0.235, global_step=693.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 695/20881 [1:03:07<30:33:28,  5.45s/it, loss=0.0972, v_num=0, train/loss_simple_step=0.0317, train/loss_vlb_step=0.000112, train/loss_step=0.0317, global_step=694.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 696/20881 [1:03:12<30:33:13,  5.45s/it, loss=0.0967, v_num=0, train/loss_simple_step=0.128, train/loss_vlb_step=0.000598, train/loss_step=0.128, global_step=695.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 697/20881 [1:03:18<30:33:17,  5.45s/it, loss=0.0949, v_num=0, train/loss_simple_step=0.160, train/loss_vlb_step=0.00274, train/loss_step=0.160, global_step=696.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 698/20881 [1:03:23<30:33:04,  5.45s/it, loss=0.0909, v_num=0, train/loss_simple_step=0.0607, train/loss_vlb_step=0.000222, train/loss_step=0.0607, global_step=697.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 699/20881 [1:03:29<30:33:08,  5.45s/it, loss=0.0839, v_num=0, train/loss_simple_step=0.035, train/loss_vlb_step=0.000123, train/loss_step=0.035, global_step=698.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 700/20881 [1:03:35<30:33:13,  5.45s/it, loss=0.0829, v_num=0, train/loss_simple_step=0.00484, train/loss_vlb_step=2.41e-5, train/loss_step=0.00484, global_step=699.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 701/20881 [1:03:41<30:33:23,  5.45s/it, loss=0.0803, v_num=0, train/loss_simple_step=0.0927, train/loss_vlb_step=0.000443, train/loss_step=0.0927, global_step=700.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 702/20881 [1:03:46<30:33:21,  5.45s/it, loss=0.0819, v_num=0, train/loss_simple_step=0.0851, train/loss_vlb_step=0.000338, train/loss_step=0.0851, global_step=701.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 703/20881 [1:03:52<30:33:34,  5.45s/it, loss=0.0824, v_num=0, train/loss_simple_step=0.076, train/loss_vlb_step=0.000361, train/loss_step=0.076, global_step=702.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 704/20881 [1:03:57<30:33:09,  5.45s/it, loss=0.085, v_num=0, train/loss_simple_step=0.0735, train/loss_vlb_step=0.000274, train/loss_step=0.0735, global_step=703.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 705/20881 [1:04:02<30:32:53,  5.45s/it, loss=0.0862, v_num=0, train/loss_simple_step=0.127, train/loss_vlb_step=0.000525, train/loss_step=0.127, global_step=704.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 706/20881 [1:04:07<30:32:40,  5.45s/it, loss=0.0938, v_num=0, train/loss_simple_step=0.179, train/loss_vlb_step=0.00172, train/loss_step=0.179, global_step=705.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 707/20881 [1:04:13<30:32:24,  5.45s/it, loss=0.097, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.000741, train/loss_step=0.124, global_step=706.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 708/20881 [1:04:18<30:32:23,  5.45s/it, loss=0.1, v_num=0, train/loss_simple_step=0.077, train/loss_vlb_step=0.000353, train/loss_step=0.077, global_step=707.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 709/20881 [1:04:23<30:32:03,  5.45s/it, loss=0.101, v_num=0, train/loss_simple_step=0.0583, train/loss_vlb_step=0.000224, train/loss_step=0.0583, global_step=708.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 710/20881 [1:04:28<30:31:55,  5.45s/it, loss=0.103, v_num=0, train/loss_simple_step=0.213, train/loss_vlb_step=0.00394, train/loss_step=0.213, global_step=709.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 711/20881 [1:04:34<30:31:59,  5.45s/it, loss=0.0988, v_num=0, train/loss_simple_step=0.0269, train/loss_vlb_step=9.59e-5, train/loss_step=0.0269, global_step=710.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 712/20881 [1:04:40<30:31:54,  5.45s/it, loss=0.0946, v_num=0, train/loss_simple_step=0.0873, train/loss_vlb_step=0.000727, train/loss_step=0.0873, global_step=711.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 713/20881 [1:04:46<30:32:08,  5.45s/it, loss=0.0988, v_num=0, train/loss_simple_step=0.101, train/loss_vlb_step=0.000868, train/loss_step=0.101, global_step=712.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 714/20881 [1:04:52<30:32:13,  5.45s/it, loss=0.0896, v_num=0, train/loss_simple_step=0.0519, train/loss_vlb_step=0.000174, train/loss_step=0.0519, global_step=713.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 715/20881 [1:04:57<30:32:14,  5.45s/it, loss=0.0915, v_num=0, train/loss_simple_step=0.0697, train/loss_vlb_step=0.000248, train/loss_step=0.0697, global_step=714.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 716/20881 [1:05:03<30:32:03,  5.45s/it, loss=0.0897, v_num=0, train/loss_simple_step=0.0912, train/loss_vlb_step=0.000458, train/loss_step=0.0912, global_step=715.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 717/20881 [1:05:08<30:32:03,  5.45s/it, loss=0.0833, v_num=0, train/loss_simple_step=0.0313, train/loss_vlb_step=0.000111, train/loss_step=0.0313, global_step=716.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 718/20881 [1:05:13<30:31:49,  5.45s/it, loss=0.0854, v_num=0, train/loss_simple_step=0.103, train/loss_vlb_step=0.000559, train/loss_step=0.103, global_step=717.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 719/20881 [1:05:18<30:31:32,  5.45s/it, loss=0.0883, v_num=0, train/loss_simple_step=0.0932, train/loss_vlb_step=0.000347, train/loss_step=0.0932, global_step=718.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 720/20881 [1:05:24<30:31:28,  5.45s/it, loss=0.0966, v_num=0, train/loss_simple_step=0.170, train/loss_vlb_step=0.00197, train/loss_step=0.170, global_step=719.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 721/20881 [1:05:30<30:31:29,  5.45s/it, loss=0.0986, v_num=0, train/loss_simple_step=0.134, train/loss_vlb_step=0.00108, train/loss_step=0.134, global_step=720.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 722/20881 [1:05:35<30:31:17,  5.45s/it, loss=0.0968, v_num=0, train/loss_simple_step=0.0481, train/loss_vlb_step=0.000165, train/loss_step=0.0481, global_step=721.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 723/20881 [1:05:40<30:31:10,  5.45s/it, loss=0.097, v_num=0, train/loss_simple_step=0.0804, train/loss_vlb_step=0.000337, train/loss_step=0.0804, global_step=722.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 724/20881 [1:05:45<30:30:51,  5.45s/it, loss=0.0996, v_num=0, train/loss_simple_step=0.126, train/loss_vlb_step=0.00152, train/loss_step=0.126, global_step=723.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 725/20881 [1:05:51<30:31:05,  5.45s/it, loss=0.104, v_num=0, train/loss_simple_step=0.220, train/loss_vlb_step=0.101, train/loss_step=0.220, global_step=724.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 726/20881 [1:05:56<30:30:52,  5.45s/it, loss=0.104, v_num=0, train/loss_simple_step=0.177, train/loss_vlb_step=0.00123, train/loss_step=0.177, global_step=725.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 727/20881 [1:06:03<30:31:06,  5.45s/it, loss=0.103, v_num=0, train/loss_simple_step=0.0983, train/loss_vlb_step=0.000606, train/loss_step=0.0983, global_step=726.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 728/20881 [1:06:07<30:30:34,  5.45s/it, loss=0.113, v_num=0, train/loss_simple_step=0.271, train/loss_vlb_step=0.00425, train/loss_step=0.271, global_step=727.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 729/20881 [1:06:12<30:30:23,  5.45s/it, loss=0.114, v_num=0, train/loss_simple_step=0.0817, train/loss_vlb_step=0.00043, train/loss_step=0.0817, global_step=728.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   3%|▎         | 730/20881 [1:06:18<30:30:21,  5.45s/it, loss=0.104, v_num=0, train/loss_simple_step=0.0105, train/loss_vlb_step=4.53e-5, train/loss_step=0.0105, global_step=729.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 731/20881 [1:06:24<30:30:23,  5.45s/it, loss=0.107, v_num=0, train/loss_simple_step=0.103, train/loss_vlb_step=0.000476, train/loss_step=0.103, global_step=730.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 732/20881 [1:06:29<30:30:09,  5.45s/it, loss=0.104, v_num=0, train/loss_simple_step=0.0142, train/loss_vlb_step=5.76e-5, train/loss_step=0.0142, global_step=731.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 733/20881 [1:06:35<30:30:16,  5.45s/it, loss=0.108, v_num=0, train/loss_simple_step=0.182, train/loss_vlb_step=0.00114, train/loss_step=0.182, global_step=732.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 734/20881 [1:06:41<30:30:47,  5.45s/it, loss=0.11, v_num=0, train/loss_simple_step=0.0905, train/loss_vlb_step=0.000469, train/loss_step=0.0905, global_step=733.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 735/20881 [1:06:47<30:30:54,  5.45s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0162, train/loss_vlb_step=6.09e-5, train/loss_step=0.0162, global_step=734.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 736/20881 [1:06:53<30:30:53,  5.45s/it, loss=0.108, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000391, train/loss_step=0.104, global_step=735.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 737/20881 [1:06:57<30:30:16,  5.45s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0259, train/loss_vlb_step=9.35e-5, train/loss_step=0.0259, global_step=736.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 738/20881 [1:07:02<30:29:41,  5.45s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0977, train/loss_vlb_step=0.000369, train/loss_step=0.0977, global_step=737.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 739/20881 [1:07:07<30:29:29,  5.45s/it, loss=0.106, v_num=0, train/loss_simple_step=0.078, train/loss_vlb_step=0.000328, train/loss_step=0.078, global_step=738.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 740/20881 [1:07:12<30:29:18,  5.45s/it, loss=0.101, v_num=0, train/loss_simple_step=0.071, train/loss_vlb_step=0.000378, train/loss_step=0.071, global_step=739.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 741/20881 [1:07:17<30:29:02,  5.45s/it, loss=0.101, v_num=0, train/loss_simple_step=0.126, train/loss_vlb_step=0.00049, train/loss_step=0.126, global_step=740.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 742/20881 [1:07:23<30:29:08,  5.45s/it, loss=0.105, v_num=0, train/loss_simple_step=0.121, train/loss_vlb_step=0.000463, train/loss_step=0.121, global_step=741.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 743/20881 [1:07:29<30:29:15,  5.45s/it, loss=0.106, v_num=0, train/loss_simple_step=0.116, train/loss_vlb_step=0.000445, train/loss_step=0.116, global_step=742.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 744/20881 [1:07:34<30:29:10,  5.45s/it, loss=0.103, v_num=0, train/loss_simple_step=0.064, train/loss_vlb_step=0.000234, train/loss_step=0.064, global_step=743.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 745/20881 [1:07:41<30:29:33,  5.45s/it, loss=0.0942, v_num=0, train/loss_simple_step=0.037, train/loss_vlb_step=0.000127, train/loss_step=0.037, global_step=744.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 746/20881 [1:07:46<30:29:16,  5.45s/it, loss=0.0927, v_num=0, train/loss_simple_step=0.146, train/loss_vlb_step=0.00422, train/loss_step=0.146, global_step=745.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 747/20881 [1:07:51<30:29:00,  5.45s/it, loss=0.0942, v_num=0, train/loss_simple_step=0.129, train/loss_vlb_step=0.00107, train/loss_step=0.129, global_step=746.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 748/20881 [1:07:56<30:28:40,  5.45s/it, loss=0.0828, v_num=0, train/loss_simple_step=0.0423, train/loss_vlb_step=0.000145, train/loss_step=0.0423, global_step=747.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 749/20881 [1:08:02<30:28:50,  5.45s/it, loss=0.0902, v_num=0, train/loss_simple_step=0.231, train/loss_vlb_step=0.00318, train/loss_step=0.231, global_step=748.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 750/20881 [1:08:07<30:28:39,  5.45s/it, loss=0.0925, v_num=0, train/loss_simple_step=0.0563, train/loss_vlb_step=0.000191, train/loss_step=0.0563, global_step=749.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 751/20881 [1:08:13<30:28:49,  5.45s/it, loss=0.0946, v_num=0, train/loss_simple_step=0.145, train/loss_vlb_step=0.000649, train/loss_step=0.145, global_step=750.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 752/20881 [1:08:18<30:28:31,  5.45s/it, loss=0.102, v_num=0, train/loss_simple_step=0.172, train/loss_vlb_step=0.0013, train/loss_step=0.172, global_step=751.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 753/20881 [1:08:24<30:28:33,  5.45s/it, loss=0.102, v_num=0, train/loss_simple_step=0.178, train/loss_vlb_step=0.000773, train/loss_step=0.178, global_step=752.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 754/20881 [1:08:29<30:28:13,  5.45s/it, loss=0.105, v_num=0, train/loss_simple_step=0.144, train/loss_vlb_step=0.00133, train/loss_step=0.144, global_step=753.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 755/20881 [1:08:35<30:28:19,  5.45s/it, loss=0.108, v_num=0, train/loss_simple_step=0.0691, train/loss_vlb_step=0.000236, train/loss_step=0.0691, global_step=754.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 756/20881 [1:08:40<30:28:07,  5.45s/it, loss=0.112, v_num=0, train/loss_simple_step=0.200, train/loss_vlb_step=0.0033, train/loss_step=0.200, global_step=755.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 757/20881 [1:08:45<30:27:56,  5.45s/it, loss=0.115, v_num=0, train/loss_simple_step=0.0754, train/loss_vlb_step=0.000417, train/loss_step=0.0754, global_step=756.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 758/20881 [1:08:52<30:28:23,  5.45s/it, loss=0.122, v_num=0, train/loss_simple_step=0.242, train/loss_vlb_step=0.00194, train/loss_step=0.242, global_step=757.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 759/20881 [1:08:58<30:28:38,  5.45s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0561, train/loss_vlb_step=0.000208, train/loss_step=0.0561, global_step=758.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 760/20881 [1:09:03<30:28:29,  5.45s/it, loss=0.118, v_num=0, train/loss_simple_step=0.0156, train/loss_vlb_step=6.12e-5, train/loss_step=0.0156, global_step=759.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 761/20881 [1:09:09<30:28:21,  5.45s/it, loss=0.118, v_num=0, train/loss_simple_step=0.115, train/loss_vlb_step=0.000597, train/loss_step=0.115, global_step=760.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 762/20881 [1:09:14<30:28:21,  5.45s/it, loss=0.122, v_num=0, train/loss_simple_step=0.201, train/loss_vlb_step=0.00128, train/loss_step=0.201, global_step=761.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 763/20881 [1:09:19<30:27:57,  5.45s/it, loss=0.126, v_num=0, train/loss_simple_step=0.193, train/loss_vlb_step=0.00162, train/loss_step=0.193, global_step=762.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 764/20881 [1:09:25<30:27:53,  5.45s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0873, train/loss_vlb_step=0.000342, train/loss_step=0.0873, global_step=763.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 765/20881 [1:09:30<30:27:46,  5.45s/it, loss=0.131, v_num=0, train/loss_simple_step=0.120, train/loss_vlb_step=0.00152, train/loss_step=0.120, global_step=764.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 766/20881 [1:09:35<30:27:35,  5.45s/it, loss=0.132, v_num=0, train/loss_simple_step=0.158, train/loss_vlb_step=0.00154, train/loss_step=0.158, global_step=765.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 767/20881 [1:09:40<30:27:22,  5.45s/it, loss=0.129, v_num=0, train/loss_simple_step=0.0783, train/loss_vlb_step=0.000271, train/loss_step=0.0783, global_step=766.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 768/20881 [1:09:46<30:27:27,  5.45s/it, loss=0.135, v_num=0, train/loss_simple_step=0.161, train/loss_vlb_step=0.00134, train/loss_step=0.161, global_step=767.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 769/20881 [1:09:52<30:27:23,  5.45s/it, loss=0.128, v_num=0, train/loss_simple_step=0.0981, train/loss_vlb_step=0.000628, train/loss_step=0.0981, global_step=768.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 770/20881 [1:09:58<30:27:32,  5.45s/it, loss=0.134, v_num=0, train/loss_simple_step=0.174, train/loss_vlb_step=0.000836, train/loss_step=0.174, global_step=769.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 771/20881 [1:10:03<30:27:14,  5.45s/it, loss=0.127, v_num=0, train/loss_simple_step=0.0038, train/loss_vlb_step=1.99e-5, train/loss_step=0.0038, global_step=770.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 772/20881 [1:10:08<30:27:04,  5.45s/it, loss=0.127, v_num=0, train/loss_simple_step=0.171, train/loss_vlb_step=0.00202, train/loss_step=0.171, global_step=771.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 773/20881 [1:10:13<30:26:54,  5.45s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0559, train/loss_vlb_step=0.00019, train/loss_step=0.0559, global_step=772.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 774/20881 [1:10:19<30:26:46,  5.45s/it, loss=0.121, v_num=0, train/loss_simple_step=0.135, train/loss_vlb_step=0.00102, train/loss_step=0.135, global_step=773.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 775/20881 [1:10:24<30:26:42,  5.45s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0718, train/loss_vlb_step=0.000245, train/loss_step=0.0718, global_step=774.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 776/20881 [1:10:30<30:26:35,  5.45s/it, loss=0.115, v_num=0, train/loss_simple_step=0.081, train/loss_vlb_step=0.000335, train/loss_step=0.081, global_step=775.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 777/20881 [1:10:35<30:26:35,  5.45s/it, loss=0.126, v_num=0, train/loss_simple_step=0.292, train/loss_vlb_step=0.102, train/loss_step=0.292, global_step=776.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 778/20881 [1:10:40<30:26:06,  5.45s/it, loss=0.119, v_num=0, train/loss_simple_step=0.114, train/loss_vlb_step=0.000568, train/loss_step=0.114, global_step=777.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 779/20881 [1:10:45<30:25:48,  5.45s/it, loss=0.121, v_num=0, train/loss_simple_step=0.0961, train/loss_vlb_step=0.000405, train/loss_step=0.0961, global_step=778.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 780/20881 [1:10:50<30:25:30,  5.45s/it, loss=0.124, v_num=0, train/loss_simple_step=0.072, train/loss_vlb_step=0.000363, train/loss_step=0.072, global_step=779.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 781/20881 [1:10:57<30:26:12,  5.45s/it, loss=0.122, v_num=0, train/loss_simple_step=0.0714, train/loss_vlb_step=0.000238, train/loss_step=0.0714, global_step=780.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 782/20881 [1:11:02<30:25:50,  5.45s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0226, train/loss_vlb_step=8.47e-5, train/loss_step=0.0226, global_step=781.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▎         | 783/20881 [1:11:07<30:25:32,  5.45s/it, loss=0.105, v_num=0, train/loss_simple_step=0.0371, train/loss_vlb_step=0.000126, train/loss_step=0.0371, global_step=782.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 784/20881 [1:11:12<30:25:23,  5.45s/it, loss=0.11, v_num=0, train/loss_simple_step=0.194, train/loss_vlb_step=0.00153, train/loss_step=0.194, global_step=783.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 785/20881 [1:11:17<30:24:58,  5.45s/it, loss=0.116, v_num=0, train/loss_simple_step=0.239, train/loss_vlb_step=0.00183, train/loss_step=0.239, global_step=784.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 786/20881 [1:11:21<30:24:32,  5.45s/it, loss=0.117, v_num=0, train/loss_simple_step=0.167, train/loss_vlb_step=0.00164, train/loss_step=0.167, global_step=785.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 787/20881 [1:11:26<30:24:11,  5.45s/it, loss=0.117, v_num=0, train/loss_simple_step=0.0751, train/loss_vlb_step=0.000382, train/loss_step=0.0751, global_step=786.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 788/20881 [1:11:31<30:23:45,  5.45s/it, loss=0.115, v_num=0, train/loss_simple_step=0.131, train/loss_vlb_step=0.00087, train/loss_step=0.131, global_step=787.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 789/20881 [1:11:36<30:23:37,  5.45s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0397, train/loss_vlb_step=0.000137, train/loss_step=0.0397, global_step=788.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 790/20881 [1:11:42<30:23:27,  5.45s/it, loss=0.107, v_num=0, train/loss_simple_step=0.0735, train/loss_vlb_step=0.000255, train/loss_step=0.0735, global_step=789.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 791/20881 [1:11:48<30:23:57,  5.45s/it, loss=0.108, v_num=0, train/loss_simple_step=0.0111, train/loss_vlb_step=4.49e-5, train/loss_step=0.0111, global_step=790.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 792/20881 [1:11:54<30:23:58,  5.45s/it, loss=0.102, v_num=0, train/loss_simple_step=0.0666, train/loss_vlb_step=0.000266, train/loss_step=0.0666, global_step=791.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 793/20881 [1:11:59<30:23:51,  5.45s/it, loss=0.104, v_num=0, train/loss_simple_step=0.0981, train/loss_vlb_step=0.000864, train/loss_step=0.0981, global_step=792.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 794/20881 [1:12:05<30:23:40,  5.45s/it, loss=0.1, v_num=0, train/loss_simple_step=0.048, train/loss_vlb_step=0.000166, train/loss_step=0.048, global_step=793.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 795/20881 [1:12:10<30:23:38,  5.45s/it, loss=0.0974, v_num=0, train/loss_simple_step=0.019, train/loss_vlb_step=7.2e-5, train/loss_step=0.019, global_step=794.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 796/20881 [1:12:16<30:23:52,  5.45s/it, loss=0.0994, v_num=0, train/loss_simple_step=0.119, train/loss_vlb_step=0.00202, train/loss_step=0.119, global_step=795.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 797/20881 [1:12:22<30:23:53,  5.45s/it, loss=0.0891, v_num=0, train/loss_simple_step=0.0877, train/loss_vlb_step=0.000377, train/loss_step=0.0877, global_step=796.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 798/20881 [1:12:27<30:23:35,  5.45s/it, loss=0.0894, v_num=0, train/loss_simple_step=0.119, train/loss_vlb_step=0.0009, train/loss_step=0.119, global_step=797.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 799/20881 [1:12:32<30:23:16,  5.45s/it, loss=0.0888, v_num=0, train/loss_simple_step=0.0844, train/loss_vlb_step=0.000307, train/loss_step=0.0844, global_step=798.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 800/20881 [1:12:38<30:23:12,  5.45s/it, loss=0.0871, v_num=0, train/loss_simple_step=0.0392, train/loss_vlb_step=0.000143, train/loss_step=0.0392, global_step=799.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 801/20881 [1:12:43<30:23:19,  5.45s/it, loss=0.0838, v_num=0, train/loss_simple_step=0.00555, train/loss_vlb_step=2.66e-5, train/loss_step=0.00555, global_step=800.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 802/20881 [1:12:49<30:23:22,  5.45s/it, loss=0.0876, v_num=0, train/loss_simple_step=0.0969, train/loss_vlb_step=0.000535, train/loss_step=0.0969, global_step=801.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 803/20881 [1:12:55<30:23:20,  5.45s/it, loss=0.0899, v_num=0, train/loss_simple_step=0.0845, train/loss_vlb_step=0.00037, train/loss_step=0.0845, global_step=802.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 804/20881 [1:13:01<30:23:22,  5.45s/it, loss=0.085, v_num=0, train/loss_simple_step=0.0959, train/loss_vlb_step=0.000336, train/loss_step=0.0959, global_step=803.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 805/20881 [1:13:06<30:23:06,  5.45s/it, loss=0.0831, v_num=0, train/loss_simple_step=0.201, train/loss_vlb_step=0.00163, train/loss_step=0.201, global_step=804.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 806/20881 [1:13:12<30:23:20,  5.45s/it, loss=0.0783, v_num=0, train/loss_simple_step=0.0706, train/loss_vlb_step=0.00031, train/loss_step=0.0706, global_step=805.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 807/20881 [1:13:18<30:23:24,  5.45s/it, loss=0.0778, v_num=0, train/loss_simple_step=0.065, train/loss_vlb_step=0.000223, train/loss_step=0.065, global_step=806.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 808/20881 [1:13:23<30:23:13,  5.45s/it, loss=0.0804, v_num=0, train/loss_simple_step=0.183, train/loss_vlb_step=0.00151, train/loss_step=0.183, global_step=807.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 809/20881 [1:13:28<30:22:52,  5.45s/it, loss=0.0885, v_num=0, train/loss_simple_step=0.202, train/loss_vlb_step=0.00181, train/loss_step=0.202, global_step=808.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 810/20881 [1:13:32<30:22:20,  5.45s/it, loss=0.0947, v_num=0, train/loss_simple_step=0.198, train/loss_vlb_step=0.0204, train/loss_step=0.198, global_step=809.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 811/20881 [1:13:38<30:22:13,  5.45s/it, loss=0.0968, v_num=0, train/loss_simple_step=0.0531, train/loss_vlb_step=0.000214, train/loss_step=0.0531, global_step=810.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 812/20881 [1:13:43<30:22:06,  5.45s/it, loss=0.0965, v_num=0, train/loss_simple_step=0.0599, train/loss_vlb_step=0.000241, train/loss_step=0.0599, global_step=811.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 813/20881 [1:13:49<30:22:05,  5.45s/it, loss=0.0966, v_num=0, train/loss_simple_step=0.100, train/loss_vlb_step=0.000414, train/loss_step=0.100, global_step=812.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 814/20881 [1:13:54<30:22:06,  5.45s/it, loss=0.0947, v_num=0, train/loss_simple_step=0.0115, train/loss_vlb_step=4.53e-5, train/loss_step=0.0115, global_step=813.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 815/20881 [1:13:59<30:21:56,  5.45s/it, loss=0.101, v_num=0, train/loss_simple_step=0.142, train/loss_vlb_step=0.000585, train/loss_step=0.142, global_step=814.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 816/20881 [1:14:04<30:21:38,  5.45s/it, loss=0.101, v_num=0, train/loss_simple_step=0.126, train/loss_vlb_step=0.000575, train/loss_step=0.126, global_step=815.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 817/20881 [1:14:10<30:21:42,  5.45s/it, loss=0.0987, v_num=0, train/loss_simple_step=0.038, train/loss_vlb_step=0.000131, train/loss_step=0.038, global_step=816.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 818/20881 [1:14:15<30:21:23,  5.45s/it, loss=0.103, v_num=0, train/loss_simple_step=0.195, train/loss_vlb_step=0.00229, train/loss_step=0.195, global_step=817.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 819/20881 [1:14:20<30:21:08,  5.45s/it, loss=0.0991, v_num=0, train/loss_simple_step=0.016, train/loss_vlb_step=6.27e-5, train/loss_step=0.016, global_step=818.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 820/20881 [1:14:25<30:20:40,  5.45s/it, loss=0.106, v_num=0, train/loss_simple_step=0.168, train/loss_vlb_step=0.000795, train/loss_step=0.168, global_step=819.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 821/20881 [1:14:29<30:20:06,  5.44s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0195, train/loss_vlb_step=7.1e-5, train/loss_step=0.0195, global_step=820.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 822/20881 [1:14:34<30:19:49,  5.44s/it, loss=0.106, v_num=0, train/loss_simple_step=0.0938, train/loss_vlb_step=0.000514, train/loss_step=0.0938, global_step=821.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 823/20881 [1:14:40<30:19:49,  5.44s/it, loss=0.108, v_num=0, train/loss_simple_step=0.120, train/loss_vlb_step=0.000603, train/loss_step=0.120, global_step=822.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 824/20881 [1:14:45<30:19:51,  5.44s/it, loss=0.108, v_num=0, train/loss_simple_step=0.104, train/loss_vlb_step=0.000388, train/loss_step=0.104, global_step=823.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 825/20881 [1:14:51<30:19:58,  5.44s/it, loss=0.105, v_num=0, train/loss_simple_step=0.129, train/loss_vlb_step=0.000748, train/loss_step=0.129, global_step=824.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 826/20881 [1:14:57<30:19:56,  5.44s/it, loss=0.113, v_num=0, train/loss_simple_step=0.231, train/loss_vlb_step=0.00254, train/loss_step=0.231, global_step=825.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 827/20881 [1:15:03<30:20:16,  5.45s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0283, train/loss_vlb_step=0.000101, train/loss_step=0.0283, global_step=826.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 828/20881 [1:15:09<30:20:04,  5.45s/it, loss=0.105, v_num=0, train/loss_simple_step=0.0625, train/loss_vlb_step=0.000236, train/loss_step=0.0625, global_step=827.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 829/20881 [1:15:15<30:20:12,  5.45s/it, loss=0.102, v_num=0, train/loss_simple_step=0.150, train/loss_vlb_step=0.00152, train/loss_step=0.150, global_step=828.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 830/20881 [1:15:21<30:20:32,  5.45s/it, loss=0.0999, v_num=0, train/loss_simple_step=0.150, train/loss_vlb_step=0.000714, train/loss_step=0.150, global_step=829.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 831/20881 [1:15:26<30:20:20,  5.45s/it, loss=0.108, v_num=0, train/loss_simple_step=0.208, train/loss_vlb_step=0.00461, train/loss_step=0.208, global_step=830.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 832/20881 [1:15:31<30:19:45,  5.45s/it, loss=0.111, v_num=0, train/loss_simple_step=0.134, train/loss_vlb_step=0.00072, train/loss_step=0.134, global_step=831.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 833/20881 [1:15:36<30:19:37,  5.45s/it, loss=0.112, v_num=0, train/loss_simple_step=0.105, train/loss_vlb_step=0.00045, train/loss_step=0.105, global_step=832.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 834/20881 [1:15:41<30:19:17,  5.45s/it, loss=0.121, v_num=0, train/loss_simple_step=0.194, train/loss_vlb_step=0.00127, train/loss_step=0.194, global_step=833.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 835/20881 [1:15:46<30:19:09,  5.44s/it, loss=0.115, v_num=0, train/loss_simple_step=0.0315, train/loss_vlb_step=0.000112, train/loss_step=0.0315, global_step=834.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 836/20881 [1:15:51<30:18:46,  5.44s/it, loss=0.113, v_num=0, train/loss_simple_step=0.0738, train/loss_vlb_step=0.000267, train/loss_step=0.0738, global_step=835.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 837/20881 [1:15:56<30:18:36,  5.44s/it, loss=0.126, v_num=0, train/loss_simple_step=0.305, train/loss_vlb_step=0.0153, train/loss_step=0.305, global_step=836.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 838/20881 [1:16:01<30:18:20,  5.44s/it, loss=0.126, v_num=0, train/loss_simple_step=0.198, train/loss_vlb_step=0.0065, train/loss_step=0.198, global_step=837.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 839/20881 [1:16:07<30:18:29,  5.44s/it, loss=0.13, v_num=0, train/loss_simple_step=0.0921, train/loss_vlb_step=0.000467, train/loss_step=0.0921, global_step=838.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 840/20881 [1:16:13<30:18:24,  5.44s/it, loss=0.134, v_num=0, train/loss_simple_step=0.250, train/loss_vlb_step=0.00223, train/loss_step=0.250, global_step=839.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 841/20881 [1:16:18<30:18:18,  5.44s/it, loss=0.134, v_num=0, train/loss_simple_step=0.0117, train/loss_vlb_step=4.92e-5, train/loss_step=0.0117, global_step=840.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 842/20881 [1:16:23<30:18:13,  5.44s/it, loss=0.131, v_num=0, train/loss_simple_step=0.0527, train/loss_vlb_step=0.000193, train/loss_step=0.0527, global_step=841.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 843/20881 [1:16:29<30:18:20,  5.44s/it, loss=0.126, v_num=0, train/loss_simple_step=0.00933, train/loss_vlb_step=4.13e-5, train/loss_step=0.00933, global_step=842.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 844/20881 [1:16:35<30:18:20,  5.44s/it, loss=0.126, v_num=0, train/loss_simple_step=0.0988, train/loss_vlb_step=0.000722, train/loss_step=0.0988, global_step=843.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 845/20881 [1:16:41<30:18:29,  5.45s/it, loss=0.123, v_num=0, train/loss_simple_step=0.084, train/loss_vlb_step=0.000359, train/loss_step=0.084, global_step=844.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 846/20881 [1:16:47<30:18:37,  5.45s/it, loss=0.117, v_num=0, train/loss_simple_step=0.102, train/loss_vlb_step=0.000618, train/loss_step=0.102, global_step=845.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 847/20881 [1:16:53<30:18:48,  5.45s/it, loss=0.116, v_num=0, train/loss_simple_step=0.00748, train/loss_vlb_step=3.21e-5, train/loss_step=0.00748, global_step=846.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 848/20881 [1:16:58<30:18:34,  5.45s/it, loss=0.118, v_num=0, train/loss_simple_step=0.103, train/loss_vlb_step=0.000788, train/loss_step=0.103, global_step=847.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 849/20881 [1:17:03<30:18:17,  5.45s/it, loss=0.117, v_num=0, train/loss_simple_step=0.121, train/loss_vlb_step=0.000988, train/loss_step=0.121, global_step=848.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 850/20881 [1:17:09<30:18:06,  5.45s/it, loss=0.111, v_num=0, train/loss_simple_step=0.0436, train/loss_vlb_step=0.000153, train/loss_step=0.0436, global_step=849.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 851/20881 [1:17:13<30:17:40,  5.44s/it, loss=0.111, v_num=0, train/loss_simple_step=0.206, train/loss_vlb_step=0.00272, train/loss_step=0.206, global_step=850.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 852/20881 [1:17:18<30:17:27,  5.44s/it, loss=0.111, v_num=0, train/loss_simple_step=0.135, train/loss_vlb_step=0.000772, train/loss_step=0.135, global_step=851.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 853/20881 [1:17:24<30:17:24,  5.44s/it, loss=0.112, v_num=0, train/loss_simple_step=0.115, train/loss_vlb_step=0.000738, train/loss_step=0.115, global_step=852.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 854/20881 [1:17:29<30:17:15,  5.44s/it, loss=0.104, v_num=0, train/loss_simple_step=0.0337, train/loss_vlb_step=0.000116, train/loss_step=0.0337, global_step=853.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 855/20881 [1:17:35<30:17:10,  5.44s/it, loss=0.111, v_num=0, train/loss_simple_step=0.183, train/loss_vlb_step=0.00135, train/loss_step=0.183, global_step=854.0]   \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 856/20881 [1:17:40<30:17:06,  5.44s/it, loss=0.112, v_num=0, train/loss_simple_step=0.0991, train/loss_vlb_step=0.000448, train/loss_step=0.0991, global_step=855.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 857/20881 [1:17:45<30:16:57,  5.44s/it, loss=0.0976, v_num=0, train/loss_simple_step=0.00644, train/loss_vlb_step=3.03e-5, train/loss_step=0.00644, global_step=856.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 858/20881 [1:17:51<30:16:46,  5.44s/it, loss=0.0912, v_num=0, train/loss_simple_step=0.0713, train/loss_vlb_step=0.000256, train/loss_step=0.0713, global_step=857.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 859/20881 [1:17:57<30:16:56,  5.44s/it, loss=0.0902, v_num=0, train/loss_simple_step=0.0721, train/loss_vlb_step=0.000273, train/loss_step=0.0721, global_step=858.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 860/20881 [1:18:02<30:16:44,  5.44s/it, loss=0.0782, v_num=0, train/loss_simple_step=0.00841, train/loss_vlb_step=3.61e-5, train/loss_step=0.00841, global_step=859.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 861/20881 [1:18:07<30:16:38,  5.44s/it, loss=0.084, v_num=0, train/loss_simple_step=0.128, train/loss_vlb_step=0.00106, train/loss_step=0.128, global_step=860.0]     \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 862/20881 [1:18:13<30:16:44,  5.45s/it, loss=0.0875, v_num=0, train/loss_simple_step=0.122, train/loss_vlb_step=0.000934, train/loss_step=0.122, global_step=861.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 863/20881 [1:18:18<30:16:26,  5.44s/it, loss=0.0944, v_num=0, train/loss_simple_step=0.148, train/loss_vlb_step=0.000631, train/loss_step=0.148, global_step=862.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 864/20881 [1:18:23<30:16:02,  5.44s/it, loss=0.0915, v_num=0, train/loss_simple_step=0.0399, train/loss_vlb_step=0.000148, train/loss_step=0.0399, global_step=863.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 865/20881 [1:18:29<30:16:08,  5.44s/it, loss=0.0911, v_num=0, train/loss_simple_step=0.0773, train/loss_vlb_step=0.000273, train/loss_step=0.0773, global_step=864.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 866/20881 [1:18:33<30:15:32,  5.44s/it, loss=0.0878, v_num=0, train/loss_simple_step=0.035, train/loss_vlb_step=0.000121, train/loss_step=0.035, global_step=865.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 867/20881 [1:18:39<30:15:35,  5.44s/it, loss=0.0949, v_num=0, train/loss_simple_step=0.150, train/loss_vlb_step=0.00114, train/loss_step=0.150, global_step=866.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 868/20881 [1:18:44<30:15:27,  5.44s/it, loss=0.0984, v_num=0, train/loss_simple_step=0.173, train/loss_vlb_step=0.00194, train/loss_step=0.173, global_step=867.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 869/20881 [1:18:50<30:15:36,  5.44s/it, loss=0.0956, v_num=0, train/loss_simple_step=0.066, train/loss_vlb_step=0.00037, train/loss_step=0.066, global_step=868.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 870/20881 [1:18:56<30:15:42,  5.44s/it, loss=0.0963, v_num=0, train/loss_simple_step=0.057, train/loss_vlb_step=0.000204, train/loss_step=0.057, global_step=869.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 871/20881 [1:19:02<30:15:43,  5.44s/it, loss=0.0962, v_num=0, train/loss_simple_step=0.204, train/loss_vlb_step=0.0175, train/loss_step=0.204, global_step=870.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 872/20881 [1:19:08<30:15:51,  5.45s/it, loss=0.102, v_num=0, train/loss_simple_step=0.252, train/loss_vlb_step=0.0236, train/loss_step=0.252, global_step=871.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 873/20881 [1:19:14<30:16:16,  5.45s/it, loss=0.0974, v_num=0, train/loss_simple_step=0.0217, train/loss_vlb_step=7.67e-5, train/loss_step=0.0217, global_step=872.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 874/20881 [1:19:20<30:16:20,  5.45s/it, loss=0.0975, v_num=0, train/loss_simple_step=0.0361, train/loss_vlb_step=0.000124, train/loss_step=0.0361, global_step=873.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 875/20881 [1:19:25<30:16:09,  5.45s/it, loss=0.0887, v_num=0, train/loss_simple_step=0.00748, train/loss_vlb_step=3.32e-5, train/loss_step=0.00748, global_step=874.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 876/20881 [1:19:31<30:16:09,  5.45s/it, loss=0.0925, v_num=0, train/loss_simple_step=0.174, train/loss_vlb_step=0.00171, train/loss_step=0.174, global_step=875.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 877/20881 [1:19:37<30:16:04,  5.45s/it, loss=0.102, v_num=0, train/loss_simple_step=0.203, train/loss_vlb_step=0.00336, train/loss_step=0.203, global_step=876.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 878/20881 [1:19:42<30:15:50,  5.45s/it, loss=0.111, v_num=0, train/loss_simple_step=0.237, train/loss_vlb_step=0.00176, train/loss_step=0.237, global_step=877.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 879/20881 [1:19:47<30:15:38,  5.45s/it, loss=0.114, v_num=0, train/loss_simple_step=0.145, train/loss_vlb_step=0.00241, train/loss_step=0.145, global_step=878.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 880/20881 [1:19:52<30:15:19,  5.45s/it, loss=0.127, v_num=0, train/loss_simple_step=0.273, train/loss_vlb_step=0.00658, train/loss_step=0.273, global_step=879.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 881/20881 [1:19:57<30:15:14,  5.45s/it, loss=0.122, v_num=0, train/loss_simple_step=0.0271, train/loss_vlb_step=9.57e-5, train/loss_step=0.0271, global_step=880.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 882/20881 [1:20:03<30:15:15,  5.45s/it, loss=0.122, v_num=0, train/loss_simple_step=0.115, train/loss_vlb_step=0.000695, train/loss_step=0.115, global_step=881.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 883/20881 [1:20:09<30:15:13,  5.45s/it, loss=0.125, v_num=0, train/loss_simple_step=0.199, train/loss_vlb_step=0.00407, train/loss_step=0.199, global_step=882.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 884/20881 [1:20:14<30:15:14,  5.45s/it, loss=0.125, v_num=0, train/loss_simple_step=0.052, train/loss_vlb_step=0.000179, train/loss_step=0.052, global_step=883.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 885/20881 [1:20:20<30:15:14,  5.45s/it, loss=0.125, v_num=0, train/loss_simple_step=0.0706, train/loss_vlb_step=0.000286, train/loss_step=0.0706, global_step=884.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 886/20881 [1:20:25<30:15:09,  5.45s/it, loss=0.137, v_num=0, train/loss_simple_step=0.278, train/loss_vlb_step=0.0106, train/loss_step=0.278, global_step=885.0]    \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 887/20881 [1:20:31<30:15:02,  5.45s/it, loss=0.136, v_num=0, train/loss_simple_step=0.137, train/loss_vlb_step=0.00347, train/loss_step=0.137, global_step=886.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 888/20881 [1:20:37<30:15:14,  5.45s/it, loss=0.136, v_num=0, train/loss_simple_step=0.171, train/loss_vlb_step=0.00249, train/loss_step=0.171, global_step=887.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 889/20881 [1:20:42<30:14:57,  5.45s/it, loss=0.135, v_num=0, train/loss_simple_step=0.0434, train/loss_vlb_step=0.000149, train/loss_step=0.0434, global_step=888.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 890/20881 [1:20:48<30:15:02,  5.45s/it, loss=0.138, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.000558, train/loss_step=0.124, global_step=889.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 891/20881 [1:20:53<30:14:40,  5.45s/it, loss=0.137, v_num=0, train/loss_simple_step=0.169, train/loss_vlb_step=0.00827, train/loss_step=0.169, global_step=890.0] \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 892/20881 [1:20:58<30:14:32,  5.45s/it, loss=0.125, v_num=0, train/loss_simple_step=0.0133, train/loss_vlb_step=5.46e-5, train/loss_step=0.0133, global_step=891.0]\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 893/20881 [1:21:04<30:14:52,  5.45s/it, loss=0.131, v_num=0, train/loss_simple_step=0.153, train/loss_vlb_step=0.00146, train/loss_step=0.153, global_step=892.0]  \n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   4%|▍         | 894/20881 [1:21:10<30:14:52,  5.45s/it, loss=0.135, v_num=0, train/loss_simple_step=0.116, train/loss_vlb_step=0.00164, train/loss_step=0.116, global_step=893.0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "resume_path = '/home/jupyter/gcs/checkpoints/control_sd21_ini.ckpt'\n",
    "batch_size = 10\n",
    "logger_freq = 300\n",
    "learning_rate = 1e-5\n",
    "sd_locked = True\n",
    "only_mid_control = False\n",
    "\n",
    "\n",
    "# First use cpu to load models. Pytorch Lightning will automatically move it to GPUs.\n",
    "model = create_model('ControlNet/models/cldm_v21.yaml').cpu()\n",
    "model.load_state_dict(load_state_dict(resume_path, location='cpu'))\n",
    "model.learning_rate = learning_rate\n",
    "model.sd_locked = sd_locked\n",
    "model.only_mid_control = only_mid_control\n",
    "\n",
    "\n",
    "# Misc\n",
    "dataset = MyDataset(\"/home/jupyter/gcs/train.txt\")\n",
    "dataloader = DataLoader(dataset, num_workers=0, batch_size=batch_size, shuffle=True)\n",
    "logger = ImageLogger(batch_frequency=logger_freq)\n",
    "trainer = pl.Trainer(gpus=1, precision=32, callbacks=[logger])\n",
    "\n",
    "\n",
    "# Train!\n",
    "trainer.fit(model, dataloader)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "my_kernel",
   "name": "pytorch-gpu.1-13.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m107"
  },
  "kernelspec": {
   "display_name": "my_kernel",
   "language": "python",
   "name": "my_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
